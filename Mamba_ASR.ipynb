{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/state-spaces/mamba.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDMmNjp0CxkJ",
        "outputId": "5291f718-b01b-4e86-aa55-624a395291ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mamba'...\n",
            "remote: Enumerating objects: 304, done.\u001b[K\n",
            "remote: Counting objects: 100% (167/167), done.\u001b[K\n",
            "remote: Compressing objects: 100% (70/70), done.\u001b[K\n",
            "remote: Total 304 (delta 123), reused 98 (delta 97), pack-reused 137\u001b[K\n",
            "Receiving objects: 100% (304/304), 508.35 KiB | 4.89 MiB/s, done.\n",
            "Resolving deltas: 100% (146/146), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YeA8IFbYJp3"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# # Installing SpeechBrain via pip\n",
        "# BRANCH = 'develop'\n",
        "# !python -m pip install git+https://github.com/speechbrain/speechbrain.git@$BRANCH\n",
        "\n",
        "# Clone SpeechBrain repository\n",
        "%%capture\n",
        "# Local installation\n",
        "!git clone https://github.com/speechbrain/speechbrain/\n",
        "%cd /content/speechbrain/\n",
        "!pip install -r requirements.txt\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsLf7mBoSDNy",
        "outputId": "36b71add-44b2-4c18-8d2c-49cf6cd64b7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-14 00:42:40--  https://www.openslr.org/resources/12/train-clean-100.tar.gz\n",
            "Resolving www.openslr.org (www.openslr.org)... 46.101.158.64\n",
            "Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://openslr.elda.org/resources/12/train-clean-100.tar.gz [following]\n",
            "--2024-04-14 00:42:40--  https://openslr.elda.org/resources/12/train-clean-100.tar.gz\n",
            "Resolving openslr.elda.org (openslr.elda.org)... 141.94.109.138, 2001:41d0:203:ad8a::\n",
            "Connecting to openslr.elda.org (openslr.elda.org)|141.94.109.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6387309499 (5.9G) [application/x-gzip]\n",
            "Saving to: ‘train-clean-100.tar.gz’\n",
            "\n",
            "train-clean-100.tar 100%[===================>]   5.95G  27.1MB/s    in 3m 43s  \n",
            "\n",
            "2024-04-14 00:46:24 (27.3 MB/s) - ‘train-clean-100.tar.gz’ saved [6387309499/6387309499]\n",
            "\n",
            "--2024-04-14 00:46:24--  https://www.openslr.org/resources/12/dev-clean.tar.gz\n",
            "Resolving www.openslr.org (www.openslr.org)... 46.101.158.64\n",
            "Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://openslr.elda.org/resources/12/dev-clean.tar.gz [following]\n",
            "--2024-04-14 00:46:25--  https://openslr.elda.org/resources/12/dev-clean.tar.gz\n",
            "Resolving openslr.elda.org (openslr.elda.org)... 141.94.109.138, 2001:41d0:203:ad8a::\n",
            "Connecting to openslr.elda.org (openslr.elda.org)|141.94.109.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 337926286 (322M) [application/x-gzip]\n",
            "Saving to: ‘dev-clean.tar.gz’\n",
            "\n",
            "dev-clean.tar.gz    100%[===================>] 322.27M  26.4MB/s    in 13s     \n",
            "\n",
            "2024-04-14 00:46:38 (25.1 MB/s) - ‘dev-clean.tar.gz’ saved [337926286/337926286]\n",
            "\n",
            "--2024-04-14 00:46:38--  https://www.openslr.org/resources/12/test-clean.tar.gz\n",
            "Resolving www.openslr.org (www.openslr.org)... 46.101.158.64\n",
            "Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://openslr.elda.org/resources/12/test-clean.tar.gz [following]\n",
            "--2024-04-14 00:46:39--  https://openslr.elda.org/resources/12/test-clean.tar.gz\n",
            "Resolving openslr.elda.org (openslr.elda.org)... 141.94.109.138, 2001:41d0:203:ad8a::\n",
            "Connecting to openslr.elda.org (openslr.elda.org)|141.94.109.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 346663984 (331M) [application/x-gzip]\n",
            "Saving to: ‘test-clean.tar.gz’\n",
            "\n",
            "test-clean.tar.gz   100%[===================>] 330.60M  27.0MB/s    in 13s     \n",
            "\n",
            "2024-04-14 00:46:52 (25.1 MB/s) - ‘test-clean.tar.gz’ saved [346663984/346663984]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.openslr.org/resources/12/train-clean-100.tar.gz\n",
        "!wget https://www.openslr.org/resources/12/dev-clean.tar.gz\n",
        "!wget https://www.openslr.org/resources/12/test-clean.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1CuuXt-R1F3"
      },
      "outputs": [],
      "source": [
        "!tar -zxf dev-clean.tar.gz\n",
        "!tar -zxf test-clean.tar.gz\n",
        "!tar -zxf train-clean-100.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7fNRqCAm6nD"
      },
      "outputs": [],
      "source": [
        "!pip install causal-conv1d>=1.2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXR2CSjNm8OL",
        "outputId": "e852e652-de71-47f5-b060-18fa969dc907"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mamba-ssm\n",
            "  Downloading mamba_ssm-1.2.0.post1.tar.gz (34 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (2.2.1+cu121)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (24.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (1.11.1.1)\n",
            "Collecting einops (from mamba-ssm)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (2.2.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->mamba-ssm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->mamba-ssm) (12.4.127)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (1.25.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->mamba-ssm) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->mamba-ssm) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mamba-ssm) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->mamba-ssm) (1.3.0)\n",
            "Building wheels for collected packages: mamba-ssm\n",
            "  Building wheel for mamba-ssm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mamba-ssm: filename=mamba_ssm-1.2.0.post1-cp310-cp310-linux_x86_64.whl size=137750683 sha256=b264292652a34fb9dd0ce880a34a4407ba7256a3338388d056769ec29a4581c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/6e/60/ddd5c574b5793a30028f2cabdacd2a3ec2276edaaa8c00fd35\n",
            "Successfully built mamba-ssm\n",
            "Installing collected packages: einops, mamba-ssm\n",
            "Successfully installed einops-0.7.0 mamba-ssm-1.2.0.post1\n"
          ]
        }
      ],
      "source": [
        "!pip install mamba-ssm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAEGHnOPapF9",
        "outputId": "21cd2aec-1de8-4954-b000-807bffe48496"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tgt\n",
            "  Downloading tgt-1.5-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tgt, unidecode\n",
            "Successfully installed tgt-1.5 unidecode-1.3.8\n",
            "Collecting git+https://github.com/huggingface/transformers@main\n",
            "  Cloning https://github.com/huggingface/transformers (to revision main) to /tmp/pip-req-build-q11qwzms\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-q11qwzms\n",
            "  Resolved https://github.com/huggingface/transformers to commit b109257f4fb8b1166e7c53cc5418632014ed53a5\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0.dev0) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0.dev0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0.dev0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0.dev0) (2024.2.2)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.40.0.dev0-py3-none-any.whl size=8888292 sha256=27664645591b54a441389dd3726e53d66da5571551ae4f478caf9cb452c208f4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ql6o_wbb/wheels/d9/3d/ab/28ae056a634730dae1213fc3321afc3fc1d207699fe3f889cf\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.38.2\n",
            "    Uninstalling transformers-4.38.2:\n",
            "      Successfully uninstalled transformers-4.38.2\n",
            "Successfully installed transformers-4.40.0.dev0\n"
          ]
        }
      ],
      "source": [
        "!pip install unidecode tgt\n",
        "!pip install git+https://github.com/huggingface/transformers@main\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNnQJ05EaLZm",
        "outputId": "2e2be577-938f-4136-86db-8021a8a4d89f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/speechbrain/speechbrain/lobes/models\n"
          ]
        }
      ],
      "source": [
        "%cd /content/speechbrain/speechbrain/lobes/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqsilQo1_ABM",
        "outputId": "265af7e7-1d63-4e79-fe5a-b393a490545f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mamba.py\n"
          ]
        }
      ],
      "source": [
        "\n",
        "%%file mamba.py\n",
        "\n",
        "import torch\n",
        "\n",
        "import speechbrain as sb\n",
        "\n",
        "from transformers import MambaConfig, MambaModel\n",
        "import torch\n",
        "import torch as nn\n",
        "\n",
        "\n",
        "\n",
        "class MultiHeadAttentionBlock(torch.nn.Module):\n",
        "  def __init__(self, d_model: int, num_heads: int, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.head_dim = d_model // num_heads\n",
        "\n",
        "        self.w_q = torch.nn.Linear(d_model, d_model)\n",
        "        self.w_k = torch.nn.Linear(d_model, d_model)\n",
        "        self.w_v = torch.nn.Linear(d_model, d_model)\n",
        "        self.w_o = torch.nn.Linear(d_model, d_model)\n",
        "\n",
        "  @staticmethod\n",
        "  def attention(q, k, v, mask, dropout: torch.nn.Dropout):\n",
        "      head_dim = q.shape[-1]\n",
        "\n",
        "      # (batch_size, num_heads, seq_len, head_dim) * (batch_size, num_heads, head_dim, seq_len) = (batch_size, num_heads, seq_len, seq_len\n",
        "      attention_scores = torch.matmul(q, k.transpose(-2, -1)) / torch.sqrt(torch.tensor(head_dim, dtype=torch.float32))\n",
        "\n",
        "      if mask is not None:\n",
        "          attention_scores = attention_scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "      attention_scores = torch.softmax(attention_scores, dim=-1) # (batch_size, num_heads, seq_len, seq_len)\n",
        "\n",
        "      if dropout is not None:\n",
        "          attention_scores = dropout(attention_scores)\n",
        "\n",
        "      return torch.matmul(attention_scores, v), attention_scores\n",
        "\n",
        "\n",
        "  def forward(self, q, k, v, mask):\n",
        "        querry = self.w_q(q)\n",
        "        key = self.w_k(k)\n",
        "        value = self.w_v(v)\n",
        "\n",
        "        # Split the querry, key and value into num_heads\n",
        "        # Shape: (batch_size, seq_len, num_heads, head_dim)\n",
        "        querry = querry.view(querry.shape[0], -1, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        key = key.view(key.shape[0], -1, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        value = value.view(value.shape[0], -1, self.num_heads, self.head_dim).permute(0, 2, 1, 3) # (batch_size, num_heads, seq_len, head_dim)\n",
        "        x, self.attention_scores = self.attention(querry, key, value, mask, self.dropout)\n",
        "\n",
        "        # Concatenate the heads\n",
        "        # Shape: (batch_size, seq_len, d_model)\n",
        "        x = x.permute(0, 2, 1, 3).contiguous().view(x.shape[0], -1, self.d_model)\n",
        "\n",
        "        return self.w_o(x)\n",
        "\n",
        "\n",
        "class MambaEncoder(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size,\n",
        "        hidden_size,\n",
        "        state_size,\n",
        "        num_hidden_layers,\n",
        "        layer_norm_epsilon,\n",
        "        pad_token_id,\n",
        "        bos_token_id,\n",
        "        eos_token_id,\n",
        "        expand,\n",
        "        conv_kernel,\n",
        "        use_bias,\n",
        "        use_conv_bias,\n",
        "        hidden_act,\n",
        "        initializer_range,\n",
        "        residual_in_fp32,\n",
        "        time_step_rank,\n",
        "        time_step_scale,\n",
        "        time_step_min,\n",
        "        time_step_max,\n",
        "        time_step_init_scheme,\n",
        "        time_step_floor,\n",
        "        rescale_prenorm_residual,\n",
        "        use_cache\n",
        "      ):\n",
        "            super().__init__()\n",
        "            self.config = MambaConfig(\n",
        "            vocab_size=vocab_size,\n",
        "            hidden_size=hidden_size,\n",
        "            state_size=state_size,\n",
        "            num_hidden_layers=num_hidden_layers,\n",
        "            layer_norm_epsilon=layer_norm_epsilon,\n",
        "            pad_token_id=pad_token_id,\n",
        "            bos_token_id=bos_token_id,\n",
        "            eos_token_id=eos_token_id,\n",
        "            expand=expand,\n",
        "            conv_kernel=conv_kernel,\n",
        "            use_bias=use_bias,\n",
        "            use_conv_bias=use_conv_bias,\n",
        "            hidden_act=hidden_act,\n",
        "            initializer_range=initializer_range,\n",
        "            residual_in_fp32=residual_in_fp32,\n",
        "            time_step_rank=time_step_rank,\n",
        "            time_step_scale=time_step_scale,\n",
        "            time_step_min=time_step_min,\n",
        "            time_step_max=time_step_max,\n",
        "            time_step_init_scheme=time_step_init_scheme,\n",
        "            time_step_floor=time_step_floor,\n",
        "            rescale_prenorm_residual=rescale_prenorm_residual,\n",
        "            use_cache=use_cache\n",
        "        )\n",
        "            self.mamba = MambaModel(self.config)\n",
        "    def forward(self,inputs_embeds = None):\n",
        "            enc_out = self.mamba(inputs_embeds = inputs_embeds)\n",
        "            return enc_out.last_hidden_state\n",
        "\n",
        "\n",
        "class MambaDecoder(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size,\n",
        "        hidden_size,\n",
        "        state_size,\n",
        "        num_hidden_layers,\n",
        "        layer_norm_epsilon,\n",
        "        pad_token_id,\n",
        "        bos_token_id,\n",
        "        eos_token_id,\n",
        "        expand,\n",
        "        conv_kernel,\n",
        "        use_bias,\n",
        "        use_conv_bias,\n",
        "        hidden_act,\n",
        "        initializer_range,\n",
        "        residual_in_fp32,\n",
        "        time_step_rank,\n",
        "        time_step_scale,\n",
        "        time_step_min,\n",
        "        time_step_max,\n",
        "        time_step_init_scheme,\n",
        "        time_step_floor,\n",
        "        rescale_prenorm_residual,\n",
        "        use_cache\n",
        "      ):\n",
        "        super().__init__()\n",
        "        self.config = MambaConfig(\n",
        "              vocab_size=vocab_size,\n",
        "              hidden_size=hidden_size,\n",
        "              state_size=state_size,\n",
        "              num_hidden_layers=num_hidden_layers,\n",
        "              layer_norm_epsilon=layer_norm_epsilon,\n",
        "              pad_token_id=pad_token_id,\n",
        "              bos_token_id=bos_token_id,\n",
        "              eos_token_id=eos_token_id,\n",
        "              expand=expand,\n",
        "              conv_kernel=conv_kernel,\n",
        "              use_bias=use_bias,\n",
        "              use_conv_bias=use_conv_bias,\n",
        "              hidden_act=hidden_act,\n",
        "              initializer_range=initializer_range,\n",
        "              residual_in_fp32=residual_in_fp32,\n",
        "              time_step_rank=time_step_rank,\n",
        "              time_step_scale=time_step_scale,\n",
        "              time_step_min=time_step_min,\n",
        "              time_step_max=time_step_max,\n",
        "              time_step_init_scheme=time_step_init_scheme,\n",
        "              time_step_floor=time_step_floor,\n",
        "              rescale_prenorm_residual=rescale_prenorm_residual,\n",
        "              use_cache=use_cache\n",
        "        )\n",
        "        self.mamba = MambaModel(self.config)\n",
        "        self.embedding = torch.nn.Embedding(self.config.vocab_size, self.config.hidden_size)\n",
        "        self.cross_attention = MultiHeadAttentionBlock(self.config.hidden_size, 4)\n",
        "        self.norm = torch.nn.LayerNorm(self.config.hidden_size)\n",
        "        #self.fc = torch.nn.Linear(self.config.hidden_size, self.config.vocab_size)\n",
        "\n",
        "    def forward(self, input_ids=None, embeds=None, encoder_output=None, src_mask=None, tgt_mask=None, cache_params=None):\n",
        "        decoder_output = self.mamba(inputs_embeds=embeds, cache_params=cache_params)\n",
        "        decoder_output = self.cross_attention(decoder_output.last_hidden_state, encoder_output, encoder_output, src_mask)\n",
        "        decoder_output = self.norm(decoder_output)\n",
        "        #logits = self.fc(decoder_output)\n",
        "\n",
        "        return decoder_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYC_TDrchGuz",
        "outputId": "d867fe58-070f-4741-8118-267d354b4330"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/speechbrain/recipes/LibriSpeech/ASR\n",
            "/content/speechbrain/recipes/LibriSpeech/ASR/mamba\n"
          ]
        }
      ],
      "source": [
        "%cd /content/speechbrain/recipes/LibriSpeech/ASR\n",
        "!mkdir mamba\n",
        "%cd mamba\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWTWNlV7dz0-",
        "outputId": "2966f7f3-6103-4670-bbc4-ef6e3395c40e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing librispeech_prepare.py\n"
          ]
        }
      ],
      "source": [
        "%%file librispeech_prepare.py\n",
        "\"\"\"\n",
        "Data preparation.\n",
        "\n",
        "Download: http://www.openslr.org/12\n",
        "\n",
        "Author\n",
        "------\n",
        " * Mirco Ravanelli, 2020\n",
        " * Ju-Chieh Chou, 2020\n",
        " * Loren Lugosch, 2020\n",
        " * Pierre Champion, 2023\n",
        " * Adel Moumen, 2024\n",
        "\"\"\"\n",
        "\n",
        "import csv\n",
        "import functools\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "from collections import Counter\n",
        "from dataclasses import dataclass\n",
        "\n",
        "from speechbrain.dataio.dataio import (\n",
        "    load_pkl,\n",
        "    merge_csvs,\n",
        "    read_audio_info,\n",
        "    save_pkl,\n",
        ")\n",
        "from speechbrain.utils.data_utils import download_file, get_all_files\n",
        "from speechbrain.utils.parallel import parallel_map\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "OPT_FILE = \"opt_librispeech_prepare.pkl\"\n",
        "SAMPLERATE = 16000\n",
        "OPEN_SLR_11_LINK = \"http://www.openslr.org/resources/11/\"\n",
        "OPEN_SLR_11_NGRAM_MODELs = [\n",
        "    \"3-gram.arpa.gz\",\n",
        "    \"3-gram.pruned.1e-7.arpa.gz\",\n",
        "    \"3-gram.pruned.3e-7.arpa.gz\",\n",
        "    \"4-gram.arpa.gz\",\n",
        "]\n",
        "\n",
        "\n",
        "def prepare_librispeech(\n",
        "    data_folder,\n",
        "    save_folder,\n",
        "    tr_splits=[],\n",
        "    dev_splits=[],\n",
        "    te_splits=[],\n",
        "    select_n_sentences=None,\n",
        "    merge_lst=[],\n",
        "    merge_name=None,\n",
        "    create_lexicon=False,\n",
        "    skip_prep=False,\n",
        "):\n",
        "    \"\"\"\n",
        "    This class prepares the csv files for the LibriSpeech dataset.\n",
        "    Download link: http://www.openslr.org/12\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    data_folder : str\n",
        "        Path to the folder where the original LibriSpeech dataset is stored.\n",
        "    save_folder : str\n",
        "        The directory where to store the csv files.\n",
        "    tr_splits : list\n",
        "        List of train splits to prepare from ['test-others','train-clean-100',\n",
        "        'train-clean-360','train-other-500'].\n",
        "    dev_splits : list\n",
        "        List of dev splits to prepare from ['dev-clean','dev-others'].\n",
        "    te_splits : list\n",
        "        List of test splits to prepare from ['test-clean','test-others'].\n",
        "    select_n_sentences : int\n",
        "        Default : None\n",
        "        If not None, only pick this many sentences.\n",
        "    merge_lst : list\n",
        "        List of librispeech splits (e.g, train-clean, train-clean-360,..) to\n",
        "        merge in a single csv file.\n",
        "    merge_name: str\n",
        "        Name of the merged csv file.\n",
        "    create_lexicon: bool\n",
        "        If True, it outputs csv files containing mapping between grapheme\n",
        "        to phonemes. Use it for training a G2P system.\n",
        "    skip_prep: bool\n",
        "        If True, data preparation is skipped.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> data_folder = 'datasets/LibriSpeech'\n",
        "    >>> tr_splits = ['train-clean-100']\n",
        "    >>> dev_splits = ['dev-clean']\n",
        "    >>> te_splits = ['test-clean']\n",
        "    >>> save_folder = 'librispeech_prepared'\n",
        "    >>> prepare_librispeech(data_folder, save_folder, tr_splits, dev_splits, te_splits)\n",
        "    \"\"\"\n",
        "\n",
        "    if skip_prep:\n",
        "        return\n",
        "    data_folder = data_folder\n",
        "    splits = tr_splits + dev_splits + te_splits\n",
        "    save_folder = save_folder\n",
        "    select_n_sentences = select_n_sentences\n",
        "    conf = {\n",
        "        \"select_n_sentences\": select_n_sentences,\n",
        "    }\n",
        "\n",
        "    # Other variables\n",
        "    # Saving folder\n",
        "    if not os.path.exists(save_folder):\n",
        "        os.makedirs(save_folder)\n",
        "\n",
        "    save_opt = os.path.join(save_folder, OPT_FILE)\n",
        "\n",
        "    # Check if this phase is already done (if so, skip it)\n",
        "    if skip(splits, save_folder, conf):\n",
        "        logger.info(\"Skipping preparation, completed in previous run.\")\n",
        "        return\n",
        "    else:\n",
        "        logger.info(\"Data_preparation...\")\n",
        "\n",
        "    # Additional checks to make sure the data folder contains Librispeech\n",
        "    check_librispeech_folders(data_folder, splits)\n",
        "\n",
        "    # create csv files for each split\n",
        "    all_texts = {}\n",
        "    for split_index in range(len(splits)):\n",
        "        split = splits[split_index]\n",
        "\n",
        "        wav_lst = get_all_files(\n",
        "            os.path.join(data_folder, split), match_and=[\".flac\"]\n",
        "        )\n",
        "\n",
        "        text_lst = get_all_files(\n",
        "            os.path.join(data_folder, split), match_and=[\"trans.txt\"]\n",
        "        )\n",
        "\n",
        "        text_dict = text_to_dict(text_lst)\n",
        "        all_texts.update(text_dict)\n",
        "\n",
        "        if select_n_sentences is not None:\n",
        "            n_sentences = select_n_sentences[split_index]\n",
        "        else:\n",
        "            n_sentences = len(wav_lst)\n",
        "\n",
        "        create_csv(save_folder, wav_lst, text_dict, split, n_sentences)\n",
        "\n",
        "    # Merging csv file if needed\n",
        "    if merge_lst and merge_name is not None:\n",
        "        merge_files = [split_libri + \".csv\" for split_libri in merge_lst]\n",
        "        merge_csvs(\n",
        "            data_folder=save_folder, csv_lst=merge_files, merged_csv=merge_name\n",
        "        )\n",
        "\n",
        "    # Create lexicon.csv and oov.csv\n",
        "    if create_lexicon:\n",
        "        create_lexicon_and_oov_csv(all_texts, save_folder)\n",
        "\n",
        "    # saving options\n",
        "    save_pkl(conf, save_opt)\n",
        "\n",
        "\n",
        "def create_lexicon_and_oov_csv(all_texts, save_folder):\n",
        "    \"\"\"\n",
        "    Creates lexicon csv files useful for training and testing a\n",
        "    grapheme-to-phoneme (G2P) model.\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    all_texts : dict\n",
        "        Dictionary containing text from the librispeech transcriptions\n",
        "    save_folder : str\n",
        "        The directory where to store the csv files.\n",
        "    \"\"\"\n",
        "    # If the lexicon file does not exist, download it\n",
        "    lexicon_url = \"http://www.openslr.org/resources/11/librispeech-lexicon.txt\"\n",
        "    lexicon_path = os.path.join(save_folder, \"librispeech-lexicon.txt\")\n",
        "\n",
        "    if not os.path.isfile(lexicon_path):\n",
        "        logger.info(\n",
        "            \"Lexicon file not found. Downloading from %s.\" % lexicon_url\n",
        "        )\n",
        "        download_file(lexicon_url, lexicon_path)\n",
        "\n",
        "    # Get list of all words in the transcripts\n",
        "    transcript_words = Counter()\n",
        "    for key in all_texts:\n",
        "        transcript_words.update(all_texts[key].split(\"_\"))\n",
        "\n",
        "    # Get list of all words in the lexicon\n",
        "    lexicon_words = []\n",
        "    lexicon_pronunciations = []\n",
        "    with open(lexicon_path, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "        for line in lines:\n",
        "            word = line.split()[0]\n",
        "            pronunciation = line.split()[1:]\n",
        "            lexicon_words.append(word)\n",
        "            lexicon_pronunciations.append(pronunciation)\n",
        "\n",
        "    # Create lexicon.csv\n",
        "    header = \"ID,duration,char,phn\\n\"\n",
        "    lexicon_csv_path = os.path.join(save_folder, \"lexicon.csv\")\n",
        "    with open(lexicon_csv_path, \"w\") as f:\n",
        "        f.write(header)\n",
        "        for idx in range(len(lexicon_words)):\n",
        "            separated_graphemes = [c for c in lexicon_words[idx]]\n",
        "            duration = len(separated_graphemes)\n",
        "            graphemes = \" \".join(separated_graphemes)\n",
        "            pronunciation_no_numbers = [\n",
        "                p.strip(\"0123456789\") for p in lexicon_pronunciations[idx]\n",
        "            ]\n",
        "            phonemes = \" \".join(pronunciation_no_numbers)\n",
        "            line = (\n",
        "                \",\".join([str(idx), str(duration), graphemes, phonemes]) + \"\\n\"\n",
        "            )\n",
        "            f.write(line)\n",
        "    logger.info(\"Lexicon written to %s.\" % lexicon_csv_path)\n",
        "\n",
        "    # Split lexicon.csv in train, validation, and test splits\n",
        "    split_lexicon(save_folder, [98, 1, 1])\n",
        "\n",
        "\n",
        "def split_lexicon(data_folder, split_ratio):\n",
        "    \"\"\"\n",
        "    Splits the lexicon.csv file into train, validation, and test csv files\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    data_folder : str\n",
        "        Path to the folder containing the lexicon.csv file to split.\n",
        "    split_ratio : list\n",
        "        List containing the training, validation, and test split ratio. Set it\n",
        "        to [80, 10, 10] for having 80% of material for training, 10% for valid,\n",
        "        and 10 for test.\n",
        "    \"\"\"\n",
        "    # Reading lexicon.csv\n",
        "    lexicon_csv_path = os.path.join(data_folder, \"lexicon.csv\")\n",
        "    with open(lexicon_csv_path, \"r\") as f:\n",
        "        lexicon_lines = f.readlines()\n",
        "    # Remove header\n",
        "    lexicon_lines = lexicon_lines[1:]\n",
        "\n",
        "    # Shuffle entries\n",
        "    random.shuffle(lexicon_lines)\n",
        "\n",
        "    # Selecting lines\n",
        "    header = \"ID,duration,char,phn\\n\"\n",
        "\n",
        "    tr_snts = int(0.01 * split_ratio[0] * len(lexicon_lines))\n",
        "    train_lines = [header] + lexicon_lines[0:tr_snts]\n",
        "    valid_snts = int(0.01 * split_ratio[1] * len(lexicon_lines))\n",
        "    valid_lines = [header] + lexicon_lines[tr_snts : tr_snts + valid_snts]\n",
        "    test_lines = [header] + lexicon_lines[tr_snts + valid_snts :]\n",
        "\n",
        "    # Saving files\n",
        "    with open(os.path.join(data_folder, \"lexicon_tr.csv\"), \"w\") as f:\n",
        "        f.writelines(train_lines)\n",
        "    with open(os.path.join(data_folder, \"lexicon_dev.csv\"), \"w\") as f:\n",
        "        f.writelines(valid_lines)\n",
        "    with open(os.path.join(data_folder, \"lexicon_test.csv\"), \"w\") as f:\n",
        "        f.writelines(test_lines)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class LSRow:\n",
        "    snt_id: str\n",
        "    spk_id: str\n",
        "    duration: float\n",
        "    file_path: str\n",
        "    words: str\n",
        "\n",
        "\n",
        "def process_line(wav_file, text_dict) -> LSRow:\n",
        "    snt_id = wav_file.split(\"/\")[-1].replace(\".flac\", \"\")\n",
        "    spk_id = \"-\".join(snt_id.split(\"-\")[0:2])\n",
        "    wrds = text_dict[snt_id]\n",
        "    wrds = \" \".join(wrds.split(\"_\"))\n",
        "\n",
        "    info = read_audio_info(wav_file)\n",
        "    duration = info.num_frames / info.sample_rate\n",
        "\n",
        "    return LSRow(\n",
        "        snt_id=snt_id,\n",
        "        spk_id=spk_id,\n",
        "        duration=duration,\n",
        "        file_path=wav_file,\n",
        "        words=wrds,\n",
        "    )\n",
        "\n",
        "\n",
        "def create_csv(save_folder, wav_lst, text_dict, split, select_n_sentences):\n",
        "    \"\"\"\n",
        "    Create the dataset csv file given a list of wav files.\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    save_folder : str\n",
        "        Location of the folder for storing the csv.\n",
        "    wav_lst : list\n",
        "        The list of wav files of a given data split.\n",
        "    text_dict : list\n",
        "        The dictionary containing the text of each sentence.\n",
        "    split : str\n",
        "        The name of the current data split.\n",
        "    select_n_sentences : int, optional\n",
        "        The number of sentences to select.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "    \"\"\"\n",
        "    # Setting path for the csv file\n",
        "    csv_file = os.path.join(save_folder, split + \".csv\")\n",
        "    if os.path.exists(csv_file):\n",
        "        logger.info(\"Csv file %s already exists, not recreating.\" % csv_file)\n",
        "        return\n",
        "\n",
        "    # Preliminary prints\n",
        "    msg = \"Creating csv lists in  %s...\" % (csv_file)\n",
        "    logger.info(msg)\n",
        "\n",
        "    csv_lines = [[\"ID\", \"duration\", \"wav\", \"spk_id\", \"wrd\"]]\n",
        "\n",
        "    snt_cnt = 0\n",
        "    line_processor = functools.partial(process_line, text_dict=text_dict)\n",
        "    # Processing all the wav files in wav_lst\n",
        "    # FLAC metadata reading is already fast, so we set a high chunk size\n",
        "    # to limit main thread CPU bottlenecks\n",
        "    for row in parallel_map(line_processor, wav_lst, chunk_size=8192):\n",
        "        csv_line = [\n",
        "            row.snt_id,\n",
        "            str(row.duration),\n",
        "            row.file_path,\n",
        "            row.spk_id,\n",
        "            row.words,\n",
        "        ]\n",
        "\n",
        "        # Appending current file to the csv_lines list\n",
        "        csv_lines.append(csv_line)\n",
        "\n",
        "        snt_cnt = snt_cnt + 1\n",
        "\n",
        "        # parallel_map guarantees element ordering so we're OK\n",
        "        if snt_cnt == select_n_sentences:\n",
        "            break\n",
        "\n",
        "    # Writing the csv_lines\n",
        "    with open(csv_file, mode=\"w\") as csv_f:\n",
        "        csv_writer = csv.writer(\n",
        "            csv_f, delimiter=\",\", quotechar='\"', quoting=csv.QUOTE_MINIMAL\n",
        "        )\n",
        "\n",
        "        for line in csv_lines:\n",
        "            csv_writer.writerow(line)\n",
        "\n",
        "    # Final print\n",
        "    msg = \"%s successfully created!\" % (csv_file)\n",
        "    logger.info(msg)\n",
        "\n",
        "\n",
        "def skip(splits, save_folder, conf):\n",
        "    \"\"\"\n",
        "    Detect when the librispeech data prep can be skipped.\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    splits : list\n",
        "        A list of the splits expected in the preparation.\n",
        "    save_folder : str\n",
        "        The location of the save directory\n",
        "    conf : dict\n",
        "        The configuration options to ensure they haven't changed.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    bool\n",
        "        if True, the preparation phase can be skipped.\n",
        "        if False, it must be done.\n",
        "    \"\"\"\n",
        "\n",
        "    # Checking csv files\n",
        "    skip = True\n",
        "\n",
        "    for split in splits:\n",
        "        if not os.path.isfile(os.path.join(save_folder, split + \".csv\")):\n",
        "            skip = False\n",
        "\n",
        "    #  Checking saved options\n",
        "    save_opt = os.path.join(save_folder, OPT_FILE)\n",
        "    if skip is True:\n",
        "        if os.path.isfile(save_opt):\n",
        "            opts_old = load_pkl(save_opt)\n",
        "            if opts_old == conf:\n",
        "                skip = True\n",
        "            else:\n",
        "                skip = False\n",
        "        else:\n",
        "            skip = False\n",
        "\n",
        "    return skip\n",
        "\n",
        "\n",
        "def text_to_dict(text_lst):\n",
        "    \"\"\"\n",
        "    This converts lines of text into a dictionary-\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    text_lst : str\n",
        "        Path to the file containing the librispeech text transcription.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "        The dictionary containing the text transcriptions for each sentence.\n",
        "\n",
        "    \"\"\"\n",
        "    # Initialization of the text dictionary\n",
        "    text_dict = {}\n",
        "    # Reading all the transcription files is text_lst\n",
        "    for file in text_lst:\n",
        "        with open(file, \"r\") as f:\n",
        "            # Reading all line of the transcription file\n",
        "            for line in f:\n",
        "                line_lst = line.strip().split(\" \")\n",
        "                text_dict[line_lst[0]] = \"_\".join(line_lst[1:])\n",
        "    return text_dict\n",
        "\n",
        "\n",
        "def check_librispeech_folders(data_folder, splits):\n",
        "    \"\"\"\n",
        "    Check if the data folder actually contains the LibriSpeech dataset.\n",
        "\n",
        "    If it does not, an error is raised.\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    data_folder : str\n",
        "        The path to the directory with the data.\n",
        "    splits : list\n",
        "        The portions of the data to check.\n",
        "\n",
        "    Raises\n",
        "    ------\n",
        "    OSError\n",
        "        If LibriSpeech is not found at the specified path.\n",
        "    \"\"\"\n",
        "    # Checking if all the splits exist\n",
        "    for split in splits:\n",
        "        split_folder = os.path.join(data_folder, split)\n",
        "        if not os.path.exists(split_folder):\n",
        "            err_msg = (\n",
        "                \"the folder %s does not exist (it is expected in the \"\n",
        "                \"Librispeech dataset)\" % split_folder\n",
        "            )\n",
        "            raise OSError(err_msg)\n",
        "\n",
        "\n",
        "def download_librispeech_vocab_text(destination):\n",
        "    \"\"\"Download librispeech vocab file and unpack it.\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    destination : str\n",
        "        Place to put vocab file.\n",
        "    \"\"\"\n",
        "    f = \"librispeech-vocab.txt\"\n",
        "    download_file(OPEN_SLR_11_LINK + f, destination)\n",
        "\n",
        "\n",
        "def download_openslr_librispeech_lm(destination, rescoring_lm=True):\n",
        "    \"\"\"Download openslr librispeech lm and unpack it.\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    destination : str\n",
        "        Place to put lm.\n",
        "    rescoring_lm : bool\n",
        "        Also download bigger 4grams model\n",
        "    \"\"\"\n",
        "    os.makedirs(destination, exist_ok=True)\n",
        "    for f in OPEN_SLR_11_NGRAM_MODELs:\n",
        "        if f.startswith(\"4\") and not rescoring_lm:\n",
        "            continue\n",
        "        d = os.path.join(destination, f)\n",
        "        download_file(OPEN_SLR_11_LINK + f, d, unpack=True)\n",
        "\n",
        "\n",
        "def download_sb_librispeech_lm(destination, rescoring_lm=True):\n",
        "    \"\"\"Download sb librispeech lm and unpack it.\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    destination : str\n",
        "        Place to put lm.\n",
        "    rescoring_lm : bool\n",
        "        Also download bigger 4grams model\n",
        "    \"\"\"\n",
        "    os.makedirs(destination, exist_ok=True)\n",
        "    download_file(\n",
        "        \"https://www.dropbox.com/scl/fi/3fkkdlliavhveb5n3nsow/3gram_lm.arpa?rlkey=jgdrluppfut1pjminf3l3y106&dl=1\",\n",
        "        os.path.join(destination, \"3-gram_sb.arpa\"),\n",
        "    )\n",
        "    if rescoring_lm:\n",
        "        download_file(\n",
        "            \"https://www.dropbox.com/scl/fi/roz46ee0ah2lvy5csno4z/4gram_lm.arpa?rlkey=2wt8ozb1mqgde9h9n9rp2yppz&dl=1\",\n",
        "            os.path.join(destination, \"4-gram_sb.arpa\"),\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4usT_KnKeAGg",
        "outputId": "860186bd-67e2-435f-e39e-1a03b265b062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘hparams’: File exists\n",
            "/content/speechbrain/recipes/LibriSpeech/ASR/mamba/hparams\n"
          ]
        }
      ],
      "source": [
        "!mkdir hparams\n",
        "%cd /content/speechbrain/recipes/LibriSpeech/ASR/mamba/hparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqyfYjNRPRfH",
        "outputId": "af46ceb0-e2c5-46bd-e395-64a3d66e366a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mamba_BPE_1000.yaml\n"
          ]
        }
      ],
      "source": [
        "%%file mamba_BPE_1000.yaml\n",
        "# ############################################################################\n",
        "# Model: E2E ASR with Mamba- based  ASR\n",
        "# Encoder: Mamba Encoder\n",
        "# Decoder: Mamba Decoder\n",
        "# Tokens: BPE with unigram\n",
        "# losses: CTC+ NLL\n",
        "# Training: Librispeech 100h\n",
        "# Authors:  William Chittavong\n",
        "# ############################################################################\n",
        "\n",
        "# Seed needs to be set at top of yaml, before objects with parameters\n",
        "seed: 2602\n",
        "__set_seed: !apply:torch.manual_seed [!ref <seed>]\n",
        "output_folder: !ref results/Mamba_100h_LM/<seed>\n",
        "output_wer_folder: !ref <output_folder>/\n",
        "save_folder: !ref <output_folder>/save\n",
        "train_log: !ref <output_folder>/train_log.txt\n",
        "\n",
        "# Language model (LM) pretraining\n",
        "# NB: To avoid mismatch, the speech recognizer must be trained with the same\n",
        "# tokenizer used for LM training. Here, we download everything from the\n",
        "# speechbrain HuggingFace repository. However, a local path pointing to a\n",
        "# directory containing the lm.ckpt and tokenizer.ckpt may also be specified\n",
        "# instead. E.g if you want to use your own LM / tokenizer.\n",
        "pretrained_lm_tokenizer_path: speechbrain/asr-crdnn-rnnlm-librispeech\n",
        "\n",
        "# Data files\n",
        "data_folder: /content/speechbrain/LibriSpeech # e,g./path/to/LibriSpeech\n",
        "\n",
        "train_splits: [\"train-clean-100\"]\n",
        "dev_splits: [\"dev-clean\"]\n",
        "test_splits: [\"test-clean\"]\n",
        "skip_prep: False\n",
        "ckpt_interval_minutes: 15 # save checkpoint every N min\n",
        "train_csv: !ref <save_folder>/train.csv\n",
        "valid_csv: !ref <save_folder>/dev-clean.csv\n",
        "test_csv:\n",
        "   - !ref <save_folder>/test-clean.csv\n",
        "\n",
        "\n",
        "# Data for augmentation\n",
        "data_folder_noise: !ref <data_folder>/noise # The noisy sequences for data augmentation will automatically be downloaded here.\n",
        "NOISE_DATASET_URL: https://www.dropbox.com/scl/fi/a09pj97s5ifan81dqhi4n/noises.zip?rlkey=j8b0n9kdjdr32o1f06t0cw5b7&dl=1\n",
        "noise_annotation: !ref <save_folder>/noise.csv #The data manifest files are created by the data preparation script\n",
        "\n",
        "####################### Training Parameters ####################################\n",
        "\n",
        "number_of_epochs: 15\n",
        "number_of_ctc_epochs: 5\n",
        "batch_size: 8\n",
        "lr: 1.0\n",
        "ctc_weight: 0.5\n",
        "sorting: ascending\n",
        "dynamic_batching: False\n",
        "precision: fp32 # bf16, fp16 or fp32\n",
        "\n",
        "# dynamic batching parameters, if used\n",
        "feats_hop_size: 0.01\n",
        "max_batch_length: 20000 # in terms of frames\n",
        "shuffle: True\n",
        "batch_ordering: random\n",
        "num_buckets: 20\n",
        "dynamic_batch_sampler:\n",
        "   max_batch_length: !ref <max_batch_length>\n",
        "   shuffle: !ref <shuffle>\n",
        "   batch_ordering: !ref <batch_ordering>\n",
        "   num_buckets: !ref <num_buckets>\n",
        "\n",
        "# Feature parameters\n",
        "sample_rate: 16000\n",
        "n_fft: 400\n",
        "n_mels: 40\n",
        "\n",
        "opt_class: !name:torch.optim.Adadelta\n",
        "   lr: !ref <lr>\n",
        "   rho: 0.95\n",
        "   eps: 1.e-8\n",
        "\n",
        "# Dataloader options\n",
        "num_workers: 4\n",
        "train_dataloader_opts:\n",
        "   num_workers: !ref <num_workers>\n",
        "   batch_size: !ref <batch_size>\n",
        "\n",
        "valid_dataloader_opts:\n",
        "   num_workers: !ref <num_workers>\n",
        "   batch_size: !ref <batch_size>\n",
        "\n",
        "test_dataloader_opts:\n",
        "   batch_size: 1\n",
        "\n",
        "####################### Model Parameters #######################################\n",
        "\n",
        "dropout: 0.15\n",
        "dnn_blocks: 2\n",
        "dnn_neurons: 512\n",
        "emb_size: 128\n",
        "dec_neurons: 1024\n",
        "blank_index: 0\n",
        "bos_index: 0\n",
        "eos_index: 0\n",
        "\n",
        "output_neurons: 1000  # Number of tokens (same as LM)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "hidden_size: 1024\n",
        "state_size: 16\n",
        "num_hidden_layers: 4\n",
        "layer_norm_epsilon: 1e-05\n",
        "pad_token_id: 0\n",
        "\n",
        "expand: 2\n",
        "conv_kernel: 4\n",
        "use_bias: False\n",
        "use_conv_bias: True\n",
        "hidden_act: 'silu'\n",
        "initializer_range: 0.1\n",
        "residual_in_fp32: True\n",
        "time_step_rank: 'auto'\n",
        "time_step_scale: 1.0\n",
        "time_step_min: 0.001\n",
        "time_step_max: 0.1\n",
        "time_step_init_scheme: 'random'\n",
        "time_step_floor: 0.0001\n",
        "rescale_prenorm_residual: False\n",
        "use_cache: True\n",
        "\n",
        "mamba_dec: !new:speechbrain.lobes.models.mamba.MambaDecoder\n",
        "  vocab_size: !ref <output_neurons>\n",
        "  hidden_size: !ref <hidden_size>\n",
        "  state_size: !ref <state_size>\n",
        "  num_hidden_layers: !ref <num_hidden_layers>\n",
        "  layer_norm_epsilon: !ref <layer_norm_epsilon>\n",
        "  pad_token_id: !ref <pad_token_id>\n",
        "  bos_token_id: !ref <bos_index>\n",
        "  eos_token_id: !ref <eos_index>\n",
        "  expand: !ref <expand>\n",
        "  conv_kernel: !ref <conv_kernel>\n",
        "  use_bias: !ref <use_bias>\n",
        "  use_conv_bias: !ref <use_conv_bias>\n",
        "  hidden_act: !ref <hidden_act>\n",
        "  initializer_range: !ref <initializer_range>\n",
        "  residual_in_fp32: !ref <residual_in_fp32>\n",
        "  time_step_rank: !ref <time_step_rank>\n",
        "  time_step_scale: !ref <time_step_scale>\n",
        "  time_step_min: !ref <time_step_min>\n",
        "  time_step_max: !ref <time_step_max>\n",
        "  time_step_init_scheme: !ref <time_step_init_scheme>\n",
        "  time_step_floor: !ref <time_step_floor>\n",
        "  rescale_prenorm_residual: !ref <rescale_prenorm_residual>\n",
        "  use_cache: !ref <use_cache>\n",
        "\n",
        "\n",
        "# Decoding parameters\n",
        "min_decode_ratio: 0.0\n",
        "max_decode_ratio: 1.0\n",
        "valid_beam_size: 80\n",
        "test_beam_size: 80\n",
        "eos_threshold: 1.5\n",
        "using_max_attn_shift: True\n",
        "max_attn_shift: 240\n",
        "temperature: 1.25\n",
        "temperature_lm: 1.25\n",
        "\n",
        "# Scoring parameters\n",
        "lm_weight: 0.5\n",
        "coverage_penalty: 1.5\n",
        "\n",
        "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
        "   limit: !ref <number_of_epochs>\n",
        "\n",
        "normalize: !new:speechbrain.processing.features.InputNormalization\n",
        "   norm_type: global\n",
        "\n",
        "compute_features: !new:speechbrain.lobes.features.Fbank\n",
        "   sample_rate: !ref <sample_rate>\n",
        "   n_fft: !ref <n_fft>\n",
        "   n_mels: !ref <n_mels>\n",
        "\n",
        "\n",
        "enc: !new:speechbrain.lobes.models.mamba.MambaEncoder\n",
        "    vocab_size: !ref <output_neurons>\n",
        "    hidden_size: !ref <hidden_size>\n",
        "    state_size: !ref <state_size>\n",
        "    num_hidden_layers: !ref <num_hidden_layers>\n",
        "    layer_norm_epsilon: !ref <layer_norm_epsilon>\n",
        "    pad_token_id: !ref <pad_token_id>\n",
        "    bos_token_id: !ref <bos_index>\n",
        "    eos_token_id: !ref <eos_index>\n",
        "    expand: !ref <expand>\n",
        "    conv_kernel: !ref <conv_kernel>\n",
        "    use_bias: !ref <use_bias>\n",
        "    use_conv_bias: !ref <use_conv_bias>\n",
        "    hidden_act: !ref <hidden_act>\n",
        "    initializer_range: !ref <initializer_range>\n",
        "    residual_in_fp32: !ref <residual_in_fp32>\n",
        "    time_step_rank: !ref <time_step_rank>\n",
        "    time_step_scale: !ref <time_step_scale>\n",
        "    time_step_min: !ref <time_step_min>\n",
        "    time_step_max: !ref <time_step_max>\n",
        "    time_step_init_scheme: !ref <time_step_init_scheme>\n",
        "    time_step_floor: !ref <time_step_floor>\n",
        "    rescale_prenorm_residual: !ref <rescale_prenorm_residual>\n",
        "    use_cache: !ref <use_cache>\n",
        "\n",
        "emb: !new:speechbrain.nnet.embedding.Embedding\n",
        "   num_embeddings: !ref <output_neurons>\n",
        "   embedding_dim: !ref <emb_size>\n",
        "\n",
        "dec: !new:speechbrain.nnet.RNN.AttentionalRNNDecoder\n",
        "   enc_dim: !ref <dnn_neurons>\n",
        "   input_size: !ref <emb_size>\n",
        "   rnn_type: gru\n",
        "   attn_type: location\n",
        "   hidden_size: !ref <dec_neurons>\n",
        "   attn_dim: 1024\n",
        "   num_layers: 1\n",
        "   scaling: 1.0\n",
        "   channels: 10\n",
        "   kernel_size: 100\n",
        "   re_init: True\n",
        "   dropout: !ref <dropout>\n",
        "\n",
        "\n",
        "feats_to_mamba_lin: !new:speechbrain.nnet.linear.Linear\n",
        "   input_size: !ref <n_mels>\n",
        "   n_neurons : !ref <hidden_size>\n",
        "\n",
        "emb_to_mamba_lin: !new:speechbrain.nnet.linear.Linear\n",
        "   input_size: !ref <emb_size>\n",
        "   n_neurons: !ref <hidden_size>\n",
        "ctc_lin: !new:speechbrain.nnet.linear.Linear\n",
        "   input_size: !ref <hidden_size>\n",
        "   n_neurons: !ref <output_neurons>\n",
        "\n",
        "seq_lin: !new:speechbrain.nnet.linear.Linear\n",
        "   input_size: !ref <hidden_size>\n",
        "   n_neurons: !ref <output_neurons>\n",
        "\n",
        "log_softmax: !new:speechbrain.nnet.activations.Softmax\n",
        "   apply_log: True\n",
        "\n",
        "ctc_cost: !name:speechbrain.nnet.losses.ctc_loss\n",
        "   blank_index: !ref <blank_index>\n",
        "\n",
        "seq_cost: !name:speechbrain.nnet.losses.nll_loss\n",
        "   label_smoothing: 0.1\n",
        "\n",
        "# This is the RNNLM that is used according to the Huggingface repository\n",
        "# NB: It has to match the pre-trained RNNLM!!\n",
        "lm_model: !new:speechbrain.lobes.models.RNNLM.RNNLM\n",
        "   output_neurons: !ref <output_neurons>\n",
        "   embedding_dim: !ref <emb_size>\n",
        "   activation: !name:torch.nn.LeakyReLU\n",
        "   dropout: 0.0\n",
        "   rnn_layers: 2\n",
        "   rnn_neurons: 2048\n",
        "   dnn_blocks: 1\n",
        "   dnn_neurons: 512\n",
        "   return_hidden: True  # For inference\n",
        "\n",
        "tokenizer: !new:sentencepiece.SentencePieceProcessor\n",
        "\n",
        "# Models\n",
        "modules:\n",
        "   enc: !ref <enc>\n",
        "   emb: !ref <emb>\n",
        "   mamba_dec: !ref <mamba_dec>\n",
        "   dec: !ref <dec>\n",
        "   ctc_lin: !ref <ctc_lin>\n",
        "   seq_lin: !ref <seq_lin>\n",
        "   feats_to_mamba_lin: !ref <feats_to_mamba_lin>\n",
        "   emb_to_mamba_lin: !ref <emb_to_mamba_lin>\n",
        "   normalize: !ref <normalize>\n",
        "   lm_model: !ref <lm_model>\n",
        "\n",
        "model: !new:torch.nn.ModuleList\n",
        "   - [!ref <enc>, !ref <emb>,!ref <mamba_dec>,!ref <dec>, !ref <ctc_lin>, !ref <seq_lin>]\n",
        "\n",
        "############################## Decoding & optimiser ############################\n",
        "\n",
        "coverage_scorer: !new:speechbrain.decoders.scorer.CoverageScorer\n",
        "   vocab_size: !ref <output_neurons>\n",
        "\n",
        "rnnlm_scorer: !new:speechbrain.decoders.scorer.RNNLMScorer\n",
        "   language_model: !ref <lm_model>\n",
        "   temperature: !ref <temperature_lm>\n",
        "\n",
        "scorer: !new:speechbrain.decoders.scorer.ScorerBuilder\n",
        "   full_scorers: [!ref <rnnlm_scorer>,\n",
        "                  !ref <coverage_scorer>]\n",
        "   weights:\n",
        "      rnnlm: !ref <lm_weight>\n",
        "      coverage: !ref <coverage_penalty>\n",
        "\n",
        "# Search\n",
        "valid_search: !new:speechbrain.decoders.S2SRNNBeamSearcher\n",
        "   embedding: !ref <emb>\n",
        "   decoder: !ref <dec>\n",
        "   linear: !ref <seq_lin>\n",
        "   bos_index: !ref <bos_index>\n",
        "   eos_index: !ref <eos_index>\n",
        "   min_decode_ratio: !ref <min_decode_ratio>\n",
        "   max_decode_ratio: !ref <max_decode_ratio>\n",
        "   beam_size: !ref <valid_beam_size>\n",
        "   eos_threshold: !ref <eos_threshold>\n",
        "   using_max_attn_shift: !ref <using_max_attn_shift>\n",
        "   max_attn_shift: !ref <max_attn_shift>\n",
        "   temperature: !ref <temperature>\n",
        "\n",
        "test_search: !new:speechbrain.decoders.S2SRNNBeamSearcher\n",
        "   embedding: !ref <emb>\n",
        "   decoder: !ref <dec>\n",
        "   linear: !ref <seq_lin>\n",
        "   bos_index: !ref <bos_index>\n",
        "   eos_index: !ref <eos_index>\n",
        "   min_decode_ratio: !ref <min_decode_ratio>\n",
        "   max_decode_ratio: !ref <max_decode_ratio>\n",
        "   beam_size: !ref <test_beam_size>\n",
        "   eos_threshold: !ref <eos_threshold>\n",
        "   using_max_attn_shift: !ref <using_max_attn_shift>\n",
        "   max_attn_shift: !ref <max_attn_shift>\n",
        "   temperature: !ref <temperature>\n",
        "   scorer: !ref <scorer>\n",
        "\n",
        "lr_annealing: !new:speechbrain.nnet.schedulers.NewBobScheduler\n",
        "   initial_value: !ref <lr>\n",
        "   improvement_threshold: 0.0025\n",
        "   annealing_factor: 0.8\n",
        "   patient: 0\n",
        "\n",
        "############################## Augmentations ###################################\n",
        "\n",
        "prepare_noise_data: !name:speechbrain.augment.preparation.prepare_dataset_from_URL\n",
        "   URL: !ref <NOISE_DATASET_URL>\n",
        "   dest_folder: !ref <data_folder_noise>\n",
        "   ext: wav\n",
        "   csv_file: !ref <noise_annotation>\n",
        "\n",
        "# Add noise to input signal\n",
        "add_noise: !new:speechbrain.augment.time_domain.AddNoise\n",
        "   csv_file: !ref <noise_annotation>\n",
        "   snr_low: 0\n",
        "   snr_high: 15\n",
        "   noise_sample_rate: !ref <sample_rate>\n",
        "   clean_sample_rate: !ref <sample_rate>\n",
        "   num_workers: !ref <num_workers>\n",
        "\n",
        "# Speed perturbation\n",
        "speed_perturb: !new:speechbrain.augment.time_domain.SpeedPerturb\n",
        "   orig_freq: !ref <sample_rate>\n",
        "   speeds: [95, 100, 105]\n",
        "\n",
        "# Frequency drop: randomly drops a number of frequency bands to zero.\n",
        "drop_freq: !new:speechbrain.augment.time_domain.DropFreq\n",
        "   drop_freq_low: 0\n",
        "   drop_freq_high: 1\n",
        "   drop_freq_count_low: 1\n",
        "   drop_freq_count_high: 3\n",
        "   drop_freq_width: 0.05\n",
        "\n",
        "# Time drop: randomly drops a number of temporal chunks.\n",
        "drop_chunk: !new:speechbrain.augment.time_domain.DropChunk\n",
        "   drop_length_low: 1000\n",
        "   drop_length_high: 2000\n",
        "   drop_count_low: 1\n",
        "   drop_count_high: 5\n",
        "\n",
        "# Augmenter: Combines previously defined augmentations to perform data augmentation\n",
        "wav_augment: !new:speechbrain.augment.augmenter.Augmenter\n",
        "   concat_original: True\n",
        "   min_augmentations: 4\n",
        "   max_augmentations: 4\n",
        "   augment_prob: 1.0\n",
        "   augmentations: [\n",
        "      !ref <add_noise>,\n",
        "      !ref <speed_perturb>,\n",
        "      !ref <drop_freq>,\n",
        "      !ref <drop_chunk>]\n",
        "\n",
        "############################## Logging and Pretrainer ##########################\n",
        "\n",
        "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
        "   checkpoints_dir: !ref <save_folder>\n",
        "   recoverables:\n",
        "      model: !ref <model>\n",
        "      scheduler: !ref <lr_annealing>\n",
        "      normalizer: !ref <normalize>\n",
        "      counter: !ref <epoch_counter>\n",
        "\n",
        "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
        "   save_file: !ref <train_log>\n",
        "\n",
        "error_rate_computer: !name:speechbrain.utils.metric_stats.ErrorRateStats\n",
        "\n",
        "cer_computer: !name:speechbrain.utils.metric_stats.ErrorRateStats\n",
        "   split_tokens: True\n",
        "\n",
        "# The pretrainer allows a mapping between pretrained files and instances that\n",
        "# are declared in the yaml. E.g here, we will download the file lm.ckpt\n",
        "# and it will be loaded into \"lm\" which is pointing to the <lm_model> defined\n",
        "# before.\n",
        "pretrainer: !new:speechbrain.utils.parameter_transfer.Pretrainer\n",
        "   collect_in: !ref <save_folder>\n",
        "   loadables:\n",
        "      lm: !ref <lm_model>\n",
        "      tokenizer: !ref <tokenizer>\n",
        "   paths:\n",
        "      lm: !ref <pretrained_lm_tokenizer_path>/lm.ckpt\n",
        "      tokenizer: !ref <pretrained_lm_tokenizer_path>/tokenizer.ckpt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRLwTRuaf2dt",
        "outputId": "8d8e61c6-6909-4f68-a32f-0861c96d8a9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/speechbrain/recipes/LibriSpeech/ASR/mamba\n"
          ]
        }
      ],
      "source": [
        "%cd /content/speechbrain/recipes/LibriSpeech/ASR/mamba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7RNrU6_cGUO",
        "outputId": "c9db8d87-b559-44f4-a596-8317b6904cc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train.py\n"
          ]
        }
      ],
      "source": [
        "%%file train.py\n",
        "#!/usr/bin/env/python3\n",
        "\"\"\"Recipe for training a sequence-to-sequence ASR system with librispeech.\n",
        "The system employs an encoder, a decoder, and an attention mechanism\n",
        "between them. Decoding is performed with beamsearch coupled with a neural\n",
        "language model.\n",
        "To run this recipe, do the following:\n",
        "> python train.py hparams/train_BPE1000.yaml\n",
        "With the default hyperparameters, the system employs a CRDNN encoder.\n",
        "The decoder is based on a standard  GRU. Beamsearch coupled with a RNN\n",
        "language model is used  on the top of decoder probabilities.\n",
        "The neural network is trained on both CTC and negative-log likelihood\n",
        "targets and sub-word units estimated with Byte Pairwise Encoding (BPE)\n",
        "are used as basic recognition tokens. Training is performed on the full\n",
        "LibriSpeech dataset (960 h).\n",
        "The experiment file is flexible enough to support a large variety of\n",
        "different systems. By properly changing the parameter files, you can try\n",
        "different encoders, decoders, tokens (e.g, characters instead of BPE),\n",
        "training split (e.g, train-clean 100 rather than the full one), and many\n",
        "other possible variations.\n",
        "This recipe assumes that the tokenizer and the LM are already trained.\n",
        "To avoid token mismatches, the tokenizer used for the acoustic model is\n",
        "the same use for the LM.  The recipe downloads the pre-trained tokenizer\n",
        "and LM.\n",
        "If you would like to train a full system from scratch do the following:\n",
        "1- Train a tokenizer (see ../../Tokenizer)\n",
        "2- Train a language model (see ../../LM)\n",
        "3- Train the acoustic model (with this code).\n",
        "Authors\n",
        " * Ju-Chieh Chou 2020\n",
        " * Mirco Ravanelli 2020\n",
        " * Abdel Heba 2020\n",
        " * Peter Plantinga 2020\n",
        " * Samuele Cornell 2020\n",
        " * Andreas Nautsch 2021\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import torch\n",
        "import logging\n",
        "import speechbrain as sb\n",
        "from speechbrain.utils.distributed import run_on_main, if_main_process\n",
        "from hyperpyyaml import load_hyperpyyaml\n",
        "from pathlib import Path\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "# Define training procedure\n",
        "class ASR(sb.Brain):\n",
        "    def compute_forward(self, batch, stage):\n",
        "        \"\"\"Forward computations from the waveform batches to the output probabilities.\"\"\"\n",
        "        batch = batch.to(self.device)\n",
        "        wavs, wav_lens = batch.sig\n",
        "        tokens_bos, _ = batch.tokens_bos\n",
        "        wavs, wav_lens = wavs.to(self.device), wav_lens.to(self.device)\n",
        "\n",
        "        # Add waveform augmentation if specified.\n",
        "        if stage == sb.Stage.TRAIN and hasattr(self.hparams, \"wav_augment\"):\n",
        "            wavs, wav_lens = self.hparams.wav_augment(wavs, wav_lens)\n",
        "            tokens_bos = self.hparams.wav_augment.replicate_labels(tokens_bos)\n",
        "\n",
        "        # Forward pass\n",
        "        feats = self.hparams.compute_features(wavs)\n",
        "        feats = self.modules.normalize(feats, wav_lens)\n",
        "\n",
        "        feats = self.modules.feats_to_mamba_lin(feats)\n",
        "        print(\"feats after linear\",feats.shape)\n",
        "        x = self.modules.enc(feats.detach())\n",
        "        print(\"\\n encoded states\",x.shape)\n",
        "        e_in = self.modules.emb(tokens_bos)  # y_in bos + tokens\n",
        "        print(\"\\n emb tokens \",e_in.shape)\n",
        "        src_mask = (torch.arange(x.size(1), device=self.device).unsqueeze(0) < wav_lens.unsqueeze(1)).unsqueeze(1).unsqueeze(1)\n",
        "        print(\"\\n src mask\", src_mask.shape)\n",
        "        tgt_mask = (torch.triu(torch.ones(e_in.size(1), e_in.size(1), device=self.device), diagonal=1) == 0).unsqueeze(0).unsqueeze(0)\n",
        "        print(\"\\n tgt mask\", tgt_mask.shape)\n",
        "        e_in = self.modules.emb_to_mamba_lin(e_in)\n",
        "        h = self.modules.mamba_dec(embeds = e_in,encoder_output =  x, src_mask=src_mask, tgt_mask=tgt_mask)\n",
        "\n",
        "        # Output layer for seq2seq log-probabilities\n",
        "        logits = self.modules.seq_lin(h)\n",
        "        p_seq = self.hparams.log_softmax(logits)\n",
        "\n",
        "        # Compute outputs\n",
        "        p_ctc, p_tokens = None, None\n",
        "        if stage == sb.Stage.TRAIN:\n",
        "            current_epoch = self.hparams.epoch_counter.current\n",
        "            if current_epoch <= self.hparams.number_of_ctc_epochs:\n",
        "                # Output layer for ctc log-probabilities\n",
        "                logits = self.modules.ctc_lin(x)\n",
        "                p_ctc = self.hparams.log_softmax(logits)\n",
        "        else:\n",
        "            if stage == sb.Stage.VALID:\n",
        "                # Get token strings from index prediction\n",
        "                p_tokens, _, _, _ = self.hparams.valid_search(x, wav_lens)\n",
        "            else:\n",
        "                p_tokens, _, _, _ = self.hparams.test_search(x, wav_lens)\n",
        "\n",
        "        return p_ctc, p_seq, wav_lens, p_tokens\n",
        "\n",
        "    def compute_objectives(self, predictions, batch, stage):\n",
        "        \"\"\"Computes the loss (CTC+NLL) given predictions and targets.\"\"\"\n",
        "\n",
        "        current_epoch = self.hparams.epoch_counter.current\n",
        "        p_ctc, p_seq, wav_lens, predicted_tokens = predictions\n",
        "\n",
        "        ids = batch.id\n",
        "        tokens_eos, tokens_eos_lens = batch.tokens_eos\n",
        "        tokens, tokens_lens = batch.tokens\n",
        "\n",
        "        # Labels must be extended if parallel augmentation or concatenated\n",
        "        # augmentation was performed on the input (increasing the time dimension)\n",
        "        if stage == sb.Stage.TRAIN and hasattr(self.hparams, \"wav_augment\"):\n",
        "            (\n",
        "                tokens,\n",
        "                tokens_lens,\n",
        "                tokens_eos,\n",
        "                tokens_eos_lens,\n",
        "            ) = self.hparams.wav_augment.replicate_multiple_labels(\n",
        "                tokens, tokens_lens, tokens_eos, tokens_eos_lens\n",
        "            )\n",
        "\n",
        "        loss_seq = self.hparams.seq_cost(\n",
        "            p_seq, tokens_eos, length=tokens_eos_lens\n",
        "        )\n",
        "\n",
        "        # Add ctc loss if necessary\n",
        "        if (\n",
        "            stage == sb.Stage.TRAIN\n",
        "            and current_epoch <= self.hparams.number_of_ctc_epochs\n",
        "        ):\n",
        "            loss_ctc = self.hparams.ctc_cost(\n",
        "                p_ctc, tokens, wav_lens, tokens_lens\n",
        "            )\n",
        "            loss = self.hparams.ctc_weight * loss_ctc\n",
        "            loss += (1 - self.hparams.ctc_weight) * loss_seq\n",
        "        else:\n",
        "            loss = loss_seq\n",
        "\n",
        "        if stage != sb.Stage.TRAIN:\n",
        "            # Decode token terms to words\n",
        "            predicted_words = [\n",
        "                self.tokenizer.decode_ids(utt_seq).split(\" \")\n",
        "                for utt_seq in predicted_tokens\n",
        "            ]\n",
        "            target_words = [wrd.split(\" \") for wrd in batch.wrd]\n",
        "            self.wer_metric.append(ids, predicted_words, target_words)\n",
        "            self.cer_metric.append(ids, predicted_words, target_words)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def on_stage_start(self, stage, epoch):\n",
        "        \"\"\"Gets called at the beginning of each epoch\"\"\"\n",
        "        if stage != sb.Stage.TRAIN:\n",
        "            self.cer_metric = self.hparams.cer_computer()\n",
        "            self.wer_metric = self.hparams.error_rate_computer()\n",
        "\n",
        "    def on_stage_end(self, stage, stage_loss, epoch):\n",
        "        \"\"\"Gets called at the end of a epoch.\"\"\"\n",
        "        # Compute/store important stats\n",
        "        stage_stats = {\"loss\": stage_loss}\n",
        "        if stage == sb.Stage.TRAIN:\n",
        "            self.train_stats = stage_stats\n",
        "        else:\n",
        "            stage_stats[\"CER\"] = self.cer_metric.summarize(\"error_rate\")\n",
        "            stage_stats[\"WER\"] = self.wer_metric.summarize(\"error_rate\")\n",
        "\n",
        "        # Perform end-of-iteration things, like annealing, logging, etc.\n",
        "        if stage == sb.Stage.VALID:\n",
        "            old_lr, new_lr = self.hparams.lr_annealing(stage_stats[\"WER\"])\n",
        "            sb.nnet.schedulers.update_learning_rate(self.optimizer, new_lr)\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                stats_meta={\"epoch\": epoch, \"lr\": old_lr},\n",
        "                train_stats=self.train_stats,\n",
        "                valid_stats=stage_stats,\n",
        "            )\n",
        "            self.checkpointer.save_and_keep_only(\n",
        "                meta={\"WER\": stage_stats[\"WER\"]},\n",
        "                min_keys=[\"WER\"],\n",
        "            )\n",
        "        elif stage == sb.Stage.TEST:\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                stats_meta={\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
        "                test_stats=stage_stats,\n",
        "            )\n",
        "            if if_main_process():\n",
        "                with open(self.hparams.test_wer_file, \"w\") as w:\n",
        "                    self.wer_metric.write_stats(w)\n",
        "\n",
        "\n",
        "def dataio_prepare(hparams):\n",
        "    \"\"\"This function prepares the datasets to be used in the brain class.\n",
        "    It also defines the data processing pipeline through user-defined functions.\n",
        "    \"\"\"\n",
        "    data_folder = hparams[\"data_folder\"]\n",
        "\n",
        "    train_data = sb.dataio.dataset.DynamicItemDataset.from_csv(\n",
        "        csv_path=hparams[\"train_csv\"],\n",
        "        replacements={\"data_root\": data_folder},\n",
        "    )\n",
        "\n",
        "    if hparams[\"sorting\"] == \"ascending\":\n",
        "        # we sort training data to speed up training and get better results.\n",
        "        train_data = train_data.filtered_sorted(sort_key=\"duration\")\n",
        "        # when sorting do not shuffle in dataloader ! otherwise is pointless\n",
        "        hparams[\"train_dataloader_opts\"][\"shuffle\"] = False\n",
        "\n",
        "    elif hparams[\"sorting\"] == \"descending\":\n",
        "        train_data = train_data.filtered_sorted(\n",
        "            sort_key=\"duration\", reverse=True\n",
        "        )\n",
        "        # when sorting do not shuffle in dataloader ! otherwise is pointless\n",
        "        hparams[\"train_dataloader_opts\"][\"shuffle\"] = False\n",
        "\n",
        "    elif hparams[\"sorting\"] == \"random\":\n",
        "        pass\n",
        "\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            \"sorting must be random, ascending or descending\"\n",
        "        )\n",
        "\n",
        "    valid_data = sb.dataio.dataset.DynamicItemDataset.from_csv(\n",
        "        csv_path=hparams[\"valid_csv\"],\n",
        "        replacements={\"data_root\": data_folder},\n",
        "    )\n",
        "    valid_data = valid_data.filtered_sorted(sort_key=\"duration\")\n",
        "\n",
        "    # test is separate\n",
        "    test_datasets = {}\n",
        "    for csv_file in hparams[\"test_csv\"]:\n",
        "        name = Path(csv_file).stem\n",
        "        test_datasets[name] = sb.dataio.dataset.DynamicItemDataset.from_csv(\n",
        "            csv_path=csv_file, replacements={\"data_root\": data_folder}\n",
        "        )\n",
        "        test_datasets[name] = test_datasets[name].filtered_sorted(\n",
        "            sort_key=\"duration\"\n",
        "        )\n",
        "\n",
        "    datasets = [train_data, valid_data] + [i for k, i in test_datasets.items()]\n",
        "\n",
        "    # We get the tokenizer as we need it to encode the labels when creating\n",
        "    # mini-batches.\n",
        "    tokenizer = hparams[\"tokenizer\"]\n",
        "\n",
        "    # 2. Define audio pipeline:\n",
        "    @sb.utils.data_pipeline.takes(\"wav\")\n",
        "    @sb.utils.data_pipeline.provides(\"sig\")\n",
        "    def audio_pipeline(wav):\n",
        "        sig = sb.dataio.dataio.read_audio(wav)\n",
        "        return sig\n",
        "\n",
        "    sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline)\n",
        "\n",
        "    # 3. Define text pipeline:\n",
        "    @sb.utils.data_pipeline.takes(\"wrd\")\n",
        "    @sb.utils.data_pipeline.provides(\n",
        "        \"wrd\", \"tokens_list\", \"tokens_bos\", \"tokens_eos\", \"tokens\"\n",
        "    )\n",
        "    def text_pipeline(wrd):\n",
        "        yield wrd\n",
        "        tokens_list = tokenizer.encode_as_ids(wrd)\n",
        "        yield tokens_list\n",
        "        tokens_bos = torch.LongTensor([hparams[\"bos_index\"]] + (tokens_list))\n",
        "        yield tokens_bos\n",
        "        tokens_eos = torch.LongTensor(tokens_list + [hparams[\"eos_index\"]])\n",
        "        yield tokens_eos\n",
        "        tokens = torch.LongTensor(tokens_list)\n",
        "        yield tokens\n",
        "\n",
        "    sb.dataio.dataset.add_dynamic_item(datasets, text_pipeline)\n",
        "\n",
        "    # 4. Set output:\n",
        "    sb.dataio.dataset.set_output_keys(\n",
        "        datasets,\n",
        "        [\"id\", \"sig\", \"wrd\", \"tokens_bos\", \"tokens_eos\", \"tokens\"],\n",
        "    )\n",
        "    train_batch_sampler = None\n",
        "    valid_batch_sampler = None\n",
        "    if hparams[\"dynamic_batching\"]:\n",
        "        from speechbrain.dataio.sampler import DynamicBatchSampler  # noqa\n",
        "        from speechbrain.dataio.dataloader import SaveableDataLoader  # noqa\n",
        "        from speechbrain.dataio.batch import PaddedBatch  # noqa\n",
        "\n",
        "        dynamic_hparams = hparams[\"dynamic_batch_sampler\"]\n",
        "        hop_size = hparams[\"feats_hop_size\"]\n",
        "\n",
        "        train_batch_sampler = DynamicBatchSampler(\n",
        "            train_data,\n",
        "            length_func=lambda x: x[\"duration\"] * (1 / hop_size),\n",
        "            **dynamic_hparams,\n",
        "        )\n",
        "\n",
        "        valid_batch_sampler = DynamicBatchSampler(\n",
        "            valid_data,\n",
        "            length_func=lambda x: x[\"duration\"] * (1 / hop_size),\n",
        "            **dynamic_hparams,\n",
        "        )\n",
        "\n",
        "    return (\n",
        "        train_data,\n",
        "        valid_data,\n",
        "        test_datasets,\n",
        "        train_batch_sampler,\n",
        "        valid_batch_sampler,\n",
        "    )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # CLI:\n",
        "    hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
        "\n",
        "    # create ddp_group with the right communication protocol\n",
        "    sb.utils.distributed.ddp_init_group(run_opts)\n",
        "\n",
        "    with open(hparams_file) as fin:\n",
        "        hparams = load_hyperpyyaml(fin, overrides)\n",
        "\n",
        "    # Create experiment directory\n",
        "    sb.create_experiment_directory(\n",
        "        experiment_directory=hparams[\"output_folder\"],\n",
        "        hyperparams_to_save=hparams_file,\n",
        "        overrides=overrides,\n",
        "    )\n",
        "\n",
        "    # Dataset prep (parsing Librispeech)\n",
        "    from librispeech_prepare import prepare_librispeech  # noqa\n",
        "\n",
        "    # multi-gpu (ddp) save data preparation\n",
        "    run_on_main(\n",
        "        prepare_librispeech,\n",
        "        kwargs={\n",
        "            \"data_folder\": hparams[\"data_folder\"],\n",
        "            \"tr_splits\": hparams[\"train_splits\"],\n",
        "            \"dev_splits\": hparams[\"dev_splits\"],\n",
        "            \"te_splits\": hparams[\"test_splits\"],\n",
        "            \"save_folder\": hparams[\"save_folder\"],\n",
        "            \"merge_lst\": hparams[\"train_splits\"],\n",
        "            \"merge_name\": \"train.csv\",\n",
        "            \"skip_prep\": hparams[\"skip_prep\"],\n",
        "        },\n",
        "    )\n",
        "    run_on_main(hparams[\"prepare_noise_data\"])\n",
        "\n",
        "    # here we create the datasets objects as well as tokenization and encoding\n",
        "    (\n",
        "        train_data,\n",
        "        valid_data,\n",
        "        test_datasets,\n",
        "        train_bsampler,\n",
        "        valid_bsampler,\n",
        "    ) = dataio_prepare(hparams)\n",
        "\n",
        "    # We download the pretrained LM from HuggingFace (or elsewhere depending on\n",
        "    # the path given in the YAML file). The tokenizer is loaded at the same time.\n",
        "    run_on_main(hparams[\"pretrainer\"].collect_files)\n",
        "    hparams[\"pretrainer\"].load_collected()\n",
        "\n",
        "    # Trainer initialization\n",
        "    asr_brain = ASR(\n",
        "        modules=hparams[\"modules\"],\n",
        "        opt_class=hparams[\"opt_class\"],\n",
        "        hparams=hparams,\n",
        "        run_opts=run_opts,\n",
        "        checkpointer=hparams[\"checkpointer\"],\n",
        "    )\n",
        "\n",
        "    # We dynamically add the tokenizer to our brain class.\n",
        "    # NB: This tokenizer corresponds to the one used for the LM!!\n",
        "    asr_brain.tokenizer = hparams[\"tokenizer\"]\n",
        "    train_dataloader_opts = hparams[\"train_dataloader_opts\"]\n",
        "    valid_dataloader_opts = hparams[\"valid_dataloader_opts\"]\n",
        "\n",
        "    if train_bsampler is not None:\n",
        "        train_dataloader_opts = {\"batch_sampler\": train_bsampler}\n",
        "    if valid_bsampler is not None:\n",
        "        valid_dataloader_opts = {\"batch_sampler\": valid_bsampler}\n",
        "\n",
        "    # Training\n",
        "    asr_brain.fit(\n",
        "        asr_brain.hparams.epoch_counter,\n",
        "        train_data,\n",
        "        valid_data,\n",
        "        train_loader_kwargs=train_dataloader_opts,\n",
        "        valid_loader_kwargs=valid_dataloader_opts,\n",
        "    )\n",
        "\n",
        "    import os\n",
        "\n",
        "    # Testing\n",
        "    if not os.path.exists(hparams[\"output_wer_folder\"]):\n",
        "        os.makedirs(hparams[\"output_wer_folder\"])\n",
        "\n",
        "    for k in test_datasets.keys():  # keys are test_clean, test_other etc\n",
        "        asr_brain.hparams.test_wer_file = os.path.join(\n",
        "            hparams[\"output_wer_folder\"], f\"wer_{k}.txt\"\n",
        "        )\n",
        "        asr_brain.evaluate(\n",
        "            test_datasets[k],\n",
        "            test_loader_kwargs=hparams[\"test_dataloader_opts\"],\n",
        "            min_key=\"WER\",\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYWbTZqYzUrT"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/speechbrain/recipes/LibriSpeech/ASR/mamba/results/Mamba_100h_LM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5s2lApuWzAj",
        "outputId": "4fe66346-6fca-4da4-c3e6-49a7dc88b707"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/python3.10/inspect.py:869: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
            "  if ismodule(module) and hasattr(module, '__file__'):\n",
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results/Mamba_100h_LM/2602\n",
            "librispeech_prepare - Data_preparation...\n",
            "librispeech_prepare - Creating csv lists in  results/Mamba_100h_LM/2602/save/train-clean-100.csv...\n",
            "  0% 0/28539 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "100% 28539/28539 [02:00<00:00, 235.95it/s]\n",
            "librispeech_prepare - results/Mamba_100h_LM/2602/save/train-clean-100.csv successfully created!\n",
            "librispeech_prepare - Creating csv lists in  results/Mamba_100h_LM/2602/save/dev-clean.csv...\n",
            "100% 2703/2703 [00:10<00:00, 246.21it/s]\n",
            "librispeech_prepare - results/Mamba_100h_LM/2602/save/dev-clean.csv successfully created!\n",
            "librispeech_prepare - Creating csv lists in  results/Mamba_100h_LM/2602/save/test-clean.csv...\n",
            "100% 2620/2620 [00:10<00:00, 242.54it/s]\n",
            "librispeech_prepare - results/Mamba_100h_LM/2602/save/test-clean.csv successfully created!\n",
            "speechbrain.dataio.dataio - results/Mamba_100h_LM/2602/save/train.csv is created.\n",
            "/content/speechbrain/LibriSpeech/noise/data.zip exists. Skipping download\n",
            "speechbrain.utils.fetching - Fetch lm.ckpt: Delegating to Huggingface hub, source speechbrain/asr-crdnn-rnnlm-librispeech.\n",
            "speechbrain.utils.fetching - HF fetch: /root/.cache/huggingface/hub/models--speechbrain--asr-crdnn-rnnlm-librispeech/snapshots/979a53a7a3f6c9291c02c040fd8ebfb2471cf8a3/lm.ckpt\n",
            "speechbrain.utils.fetching - Fetch tokenizer.ckpt: Delegating to Huggingface hub, source speechbrain/asr-crdnn-rnnlm-librispeech.\n",
            "speechbrain.utils.fetching - HF fetch: /root/.cache/huggingface/hub/models--speechbrain--asr-crdnn-rnnlm-librispeech/snapshots/979a53a7a3f6c9291c02c040fd8ebfb2471cf8a3/tokenizer.ckpt\n",
            "speechbrain.utils.parameter_transfer - Loading pretrained files for: lm, tokenizer\n",
            "speechbrain.core - Info: precision arg from hparam file is used\n",
            "speechbrain.core - Info: ckpt_interval_minutes arg from hparam file is used\n",
            "speechbrain.core - Gradscaler enabled: False. Using precision: fp32.\n",
            "speechbrain.core - ASR Model Statistics:\n",
            "* Total Number of Trainable Parameters: 127.0M\n",
            "* Total Number of Parameters: 127.0M\n",
            "* Trainable Parameters represent 100.0000% of the total size.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "speechbrain.utils.checkpoints - Would load a checkpoint here, but none found yet.\n",
            "speechbrain.utils.epoch_loop - Going into epoch 1\n",
            "  0% 0/3568 [00:00<?, ?it/s]feats after linear torch.Size([16, 197, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 197, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 9, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 197])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 9, 9])\n",
            "  0% 1/3568 [00:05<5:02:41,  5.09s/it, train_loss=121]feats after linear torch.Size([16, 205, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 205, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 12, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 205])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 12, 12])\n",
            "  0% 2/3568 [00:05<2:17:07,  2.31s/it, train_loss=96.4]feats after linear torch.Size([16, 200, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 200, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 16, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 200])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 16, 16])\n",
            "  0% 3/3568 [00:05<1:22:19,  1.39s/it, train_loss=69.8]feats after linear torch.Size([16, 203, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 203, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 15, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 203])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 15, 15])\n",
            "  0% 4/3568 [00:06<56:54,  1.04it/s, train_loss=54.7]  feats after linear torch.Size([16, 206, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 206, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 17, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 206])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 17, 17])\n",
            "  0% 5/3568 [00:06<43:00,  1.38it/s, train_loss=45.4]feats after linear torch.Size([16, 209, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 209, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 11, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 209])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 11, 11])\n",
            "  0% 6/3568 [00:06<35:34,  1.67it/s, train_loss=39.3]feats after linear torch.Size([16, 222, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 222, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 13, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 222])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 13, 13])\n",
            "  0% 7/3568 [00:06<29:36,  2.00it/s, train_loss=34.8]feats after linear torch.Size([16, 213, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 213, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 14, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 213])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 14, 14])\n",
            "  0% 8/3568 [00:07<26:32,  2.24it/s, train_loss=31.3]feats after linear torch.Size([16, 226, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 226, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 13, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 226])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 13, 13])\n",
            "  0% 9/3568 [00:07<23:59,  2.47it/s, train_loss=28.6]feats after linear torch.Size([16, 217, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 217, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 12, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 217])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 12, 12])\n",
            "  0% 10/3568 [00:07<22:25,  2.64it/s, train_loss=26.4]feats after linear torch.Size([16, 219, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 219, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 12, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 219])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 12, 12])\n",
            "  0% 11/3568 [00:08<22:04,  2.69it/s, train_loss=24.6]feats after linear torch.Size([16, 230, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 230, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 14, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 230])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 14, 14])\n",
            "  0% 12/3568 [00:08<21:03,  2.81it/s, train_loss=23.1]feats after linear torch.Size([16, 232, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 232, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 17, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 232])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 17, 17])\n",
            "  0% 13/3568 [00:08<20:13,  2.93it/s, train_loss=21.9]feats after linear torch.Size([16, 222, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 222, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 15, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 222])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 15, 15])\n",
            "  0% 14/3568 [00:09<19:49,  2.99it/s, train_loss=20.8]feats after linear torch.Size([16, 223, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 223, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 13, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 223])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 13, 13])\n",
            "  0% 15/3568 [00:09<20:36,  2.87it/s, train_loss=19.9]feats after linear torch.Size([16, 236, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 236, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 16, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 236])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 16, 16])\n",
            "  0% 16/3568 [00:10<21:09,  2.80it/s, train_loss=19.1]feats after linear torch.Size([16, 238, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 238, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 18, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 238])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 18, 18])\n",
            "  0% 17/3568 [00:10<20:42,  2.86it/s, train_loss=18.4]feats after linear torch.Size([16, 228, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 228, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 19, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 228])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 19, 19])\n",
            "  1% 18/3568 [00:10<20:56,  2.82it/s, train_loss=17.7]feats after linear torch.Size([16, 230, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 230, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 19, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 230])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 19, 19])\n",
            "  1% 19/3568 [00:11<20:19,  2.91it/s, train_loss=17.1]feats after linear torch.Size([16, 242, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 242, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 15, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 242])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 15, 15])\n",
            "  1% 20/3568 [00:11<20:20,  2.91it/s, train_loss=16.6]feats after linear torch.Size([16, 232, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 232, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 15, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 232])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 15, 15])\n",
            "  1% 21/3568 [00:11<19:38,  3.01it/s, train_loss=16.1]feats after linear torch.Size([16, 233, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 233, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 17, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 233])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 17, 17])\n",
            "  1% 22/3568 [00:12<21:39,  2.73it/s, train_loss=15.7]feats after linear torch.Size([16, 246, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 246, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 15, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 246])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 15, 15])\n",
            "  1% 23/3568 [00:12<21:25,  2.76it/s, train_loss=15.3]feats after linear torch.Size([16, 236, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 236, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 13, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 236])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 13, 13])\n",
            "  1% 24/3568 [00:12<20:27,  2.89it/s, train_loss=14.9]feats after linear torch.Size([16, 238, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 238, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 15, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 238])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 15, 15])\n",
            "  1% 25/3568 [00:13<20:50,  2.83it/s, train_loss=14.5]feats after linear torch.Size([16, 238, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 238, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 14, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 238])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 14, 14])\n",
            "  1% 26/3568 [00:13<20:55,  2.82it/s, train_loss=14.2]feats after linear torch.Size([16, 240, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 240, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 17, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 240])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 17, 17])\n",
            "  1% 27/3568 [00:14<23:50,  2.48it/s, train_loss=13.9]feats after linear torch.Size([16, 242, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 242, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 15, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 242])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 15, 15])\n",
            "  1% 28/3568 [00:14<22:48,  2.59it/s, train_loss=13.7]feats after linear torch.Size([16, 255, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 255, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 18, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 255])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 18, 18])\n",
            "  1% 29/3568 [00:14<23:42,  2.49it/s, train_loss=13.4]feats after linear torch.Size([16, 244, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 244, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 18, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 244])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 18, 18])\n",
            "  1% 30/3568 [00:15<23:55,  2.47it/s, train_loss=13.2]feats after linear torch.Size([16, 245, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 245, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 16, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 245])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 16, 16])\n",
            "  1% 31/3568 [00:15<24:20,  2.42it/s, train_loss=12.9]feats after linear torch.Size([16, 246, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 246, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 19, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 246])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 19, 19])\n",
            "  1% 32/3568 [00:16<27:06,  2.17it/s, train_loss=12.7]feats after linear torch.Size([16, 248, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 248, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 14, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 248])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 14, 14])\n",
            "  1% 33/3568 [00:16<26:18,  2.24it/s, train_loss=12.6]feats after linear torch.Size([16, 249, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 249, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 16, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 249])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 16, 16])\n",
            "  1% 34/3568 [00:16<24:24,  2.41it/s, train_loss=12.4]feats after linear torch.Size([16, 262, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 262, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 19, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 262])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 19, 19])\n",
            "  1% 35/3568 [00:17<23:18,  2.53it/s, train_loss=12.2]feats after linear torch.Size([16, 264, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 264, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 18, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 264])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 18, 18])\n",
            "  1% 36/3568 [00:17<22:36,  2.60it/s, train_loss=12]feats after linear torch.Size([16, 253, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 253, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 17, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 253])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 17, 17])\n",
            "  1% 37/3568 [00:18<21:42,  2.71it/s, train_loss=11.9]feats after linear torch.Size([16, 267, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 267, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 16, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 267])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 16, 16])\n",
            "  1% 38/3568 [00:18<22:12,  2.65it/s, train_loss=11.7]feats after linear torch.Size([16, 256, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 256, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 18, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 256])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 18, 18])\n",
            "  1% 39/3568 [00:18<22:07,  2.66it/s, train_loss=11.6]feats after linear torch.Size([16, 270, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 270, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 21, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 270])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 21, 21])\n",
            "  1% 40/3568 [00:19<22:17,  2.64it/s, train_loss=11.5]feats after linear torch.Size([16, 260, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 260, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 17, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 260])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 17, 17])\n",
            "  1% 41/3568 [00:19<22:14,  2.64it/s, train_loss=11.3]feats after linear torch.Size([16, 262, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 262, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 15, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 262])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 15, 15])\n",
            "  1% 42/3568 [00:19<22:25,  2.62it/s, train_loss=11.2]feats after linear torch.Size([16, 276, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 276, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 18, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 276])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 18, 18])\n",
            "  1% 43/3568 [00:20<23:28,  2.50it/s, train_loss=11.1]feats after linear torch.Size([16, 266, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 266, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 15, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 266])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 15, 15])\n",
            "  1% 44/3568 [00:20<23:19,  2.52it/s, train_loss=11]feats after linear torch.Size([16, 268, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 268, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 19, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 268])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 19, 19])\n",
            "  1% 45/3568 [00:21<22:58,  2.55it/s, train_loss=10.9]feats after linear torch.Size([16, 269, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 269, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 16, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 269])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 16, 16])\n",
            "  1% 46/3568 [00:21<25:12,  2.33it/s, train_loss=10.8]feats after linear torch.Size([16, 270, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 270, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 17, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 270])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 17, 17])\n",
            "  1% 47/3568 [00:22<23:52,  2.46it/s, train_loss=10.7]feats after linear torch.Size([16, 271, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 271, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 19, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 271])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 19, 19])\n",
            "  1% 48/3568 [00:22<25:12,  2.33it/s, train_loss=10.6]feats after linear torch.Size([16, 272, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 272, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 17, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 272])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 17, 17])\n",
            "  1% 49/3568 [00:22<24:07,  2.43it/s, train_loss=10.5]feats after linear torch.Size([16, 274, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 274, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 15, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 274])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 15, 15])\n",
            "  1% 50/3568 [00:23<24:00,  2.44it/s, train_loss=10.4]feats after linear torch.Size([16, 275, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 275, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 21, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 275])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 21, 21])\n",
            "  1% 51/3568 [00:23<23:44,  2.47it/s, train_loss=10.3]feats after linear torch.Size([16, 290, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 290, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 17, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 290])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 17, 17])\n",
            "  1% 52/3568 [00:24<24:06,  2.43it/s, train_loss=10.2]feats after linear torch.Size([16, 277, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 277, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 20, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 277])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 20, 20])\n",
            "  1% 53/3568 [00:24<24:27,  2.39it/s, train_loss=10.1]feats after linear torch.Size([16, 278, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 278, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 18, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 278])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 18, 18])\n",
            "  2% 54/3568 [00:24<24:43,  2.37it/s, train_loss=10.1]feats after linear torch.Size([16, 279, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 279, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 19, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 279])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 19, 19])\n",
            "  2% 55/3568 [00:25<25:20,  2.31it/s, train_loss=10]feats after linear torch.Size([16, 294, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 294, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 17, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 294])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 17, 17])\n",
            "  2% 56/3568 [00:25<24:22,  2.40it/s, train_loss=9.94]feats after linear torch.Size([16, 282, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 282, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 25, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 282])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 25, 25])\n",
            "  2% 57/3568 [00:26<24:25,  2.40it/s, train_loss=9.87]feats after linear torch.Size([16, 283, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 283, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 15, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 283])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 15, 15])\n",
            "  2% 58/3568 [00:26<23:58,  2.44it/s, train_loss=9.81]feats after linear torch.Size([16, 284, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 284, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 19, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 284])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 19, 19])\n",
            "  2% 59/3568 [00:27<24:15,  2.41it/s, train_loss=9.75]feats after linear torch.Size([16, 300, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 300, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 16, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 300])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 16, 16])\n",
            "  2% 60/3568 [00:27<28:13,  2.07it/s, train_loss=9.69]feats after linear torch.Size([16, 302, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 302, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 20, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 302])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 20, 20])\n",
            "  2% 61/3568 [00:28<27:16,  2.14it/s, train_loss=9.63]feats after linear torch.Size([16, 302, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 302, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 21, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 302])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 21, 21])\n",
            "  2% 62/3568 [00:28<27:11,  2.15it/s, train_loss=9.57]feats after linear torch.Size([16, 304, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 304, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 21, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 304])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 21, 21])\n",
            "  2% 63/3568 [00:29<26:15,  2.23it/s, train_loss=9.52]feats after linear torch.Size([16, 290, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 290, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 22, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 290])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 22, 22])\n",
            "  2% 64/3568 [00:29<26:24,  2.21it/s, train_loss=9.46]feats after linear torch.Size([16, 292, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 292, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 17, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 292])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 17, 17])\n",
            "  2% 65/3568 [00:29<26:54,  2.17it/s, train_loss=9.41]feats after linear torch.Size([16, 293, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 293, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 25, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 293])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 25, 25])\n",
            "  2% 66/3568 [00:30<25:39,  2.27it/s, train_loss=9.36]feats after linear torch.Size([16, 308, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 308, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 18, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 308])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 18, 18])\n",
            "  2% 67/3568 [00:30<25:08,  2.32it/s, train_loss=9.32]feats after linear torch.Size([16, 295, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 295, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 23, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 295])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 23, 23])\n",
            "  2% 68/3568 [00:31<24:44,  2.36it/s, train_loss=9.27]feats after linear torch.Size([16, 295, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 295, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 23, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 295])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 23, 23])\n",
            "  2% 69/3568 [00:31<24:00,  2.43it/s, train_loss=9.22]feats after linear torch.Size([16, 297, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 297, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 20, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 297])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 20, 20])\n",
            "  2% 70/3568 [00:31<24:08,  2.41it/s, train_loss=9.18]feats after linear torch.Size([16, 298, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 298, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 21, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 298])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 21, 21])\n",
            "  2% 71/3568 [00:32<24:00,  2.43it/s, train_loss=9.13]feats after linear torch.Size([16, 298, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 298, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 20, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 298])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 20, 20])\n",
            "  2% 72/3568 [00:32<23:59,  2.43it/s, train_loss=9.09]feats after linear torch.Size([16, 315, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 315, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 19, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 315])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 19, 19])\n",
            "  2% 73/3568 [00:33<24:11,  2.41it/s, train_loss=9.05]feats after linear torch.Size([16, 316, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 316, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 17, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 316])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 17, 17])\n",
            "  2% 74/3568 [00:33<23:52,  2.44it/s, train_loss=9.01]feats after linear torch.Size([16, 318, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 318, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 22, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 318])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 22, 22])\n",
            "  2% 75/3568 [00:34<24:02,  2.42it/s, train_loss=8.97]feats after linear torch.Size([16, 305, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 305, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 20, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 305])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 20, 20])\n",
            "  2% 76/3568 [00:34<23:46,  2.45it/s, train_loss=8.94]feats after linear torch.Size([16, 321, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 321, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 21, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 321])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 21, 21])\n",
            "  2% 77/3568 [00:34<24:23,  2.39it/s, train_loss=8.9]feats after linear torch.Size([16, 308, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 308, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 22, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 308])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 22, 22])\n",
            "  2% 78/3568 [00:35<24:49,  2.34it/s, train_loss=8.86]feats after linear torch.Size([16, 309, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 309, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 21, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 309])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 21, 21])\n",
            "  2% 79/3568 [00:35<24:36,  2.36it/s, train_loss=8.82]feats after linear torch.Size([16, 326, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 326, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 20, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 326])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 20, 20])\n",
            "  2% 80/3568 [00:36<24:47,  2.34it/s, train_loss=8.79]feats after linear torch.Size([16, 312, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 312, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 22, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 312])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 22, 22])\n",
            "  2% 81/3568 [00:36<25:42,  2.26it/s, train_loss=8.76]feats after linear torch.Size([16, 329, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 329, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 22, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 329])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 22, 22])\n",
            "  2% 82/3568 [00:37<25:42,  2.26it/s, train_loss=8.73]feats after linear torch.Size([16, 314, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 314, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 21, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 314])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 21, 21])\n",
            "  2% 83/3568 [00:37<25:24,  2.29it/s, train_loss=8.69]feats after linear torch.Size([16, 331, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 331, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 24, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 331])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 24, 24])\n",
            "  2% 84/3568 [00:37<24:59,  2.32it/s, train_loss=8.67]feats after linear torch.Size([16, 316, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 316, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 21, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 316])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 21, 21])\n",
            "  2% 85/3568 [00:38<24:24,  2.38it/s, train_loss=8.64]feats after linear torch.Size([16, 317, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 317, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 27, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 317])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 27, 27])\n",
            "  2% 86/3568 [00:38<24:07,  2.41it/s, train_loss=8.61]feats after linear torch.Size([16, 333, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 333, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 19, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 333])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 19, 19])\n",
            "  2% 87/3568 [00:39<24:48,  2.34it/s, train_loss=8.58]feats after linear torch.Size([16, 318, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 318, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 17, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 318])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 17, 17])\n",
            "  2% 88/3568 [00:39<24:32,  2.36it/s, train_loss=8.55]feats after linear torch.Size([16, 337, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 337, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 18, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 337])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 18, 18])\n",
            "  2% 89/3568 [00:40<25:21,  2.29it/s, train_loss=8.52]feats after linear torch.Size([16, 322, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 322, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 19, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 322])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 19, 19])\n",
            "  3% 90/3568 [00:40<27:07,  2.14it/s, train_loss=8.49]feats after linear torch.Size([16, 323, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 323, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 24, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 323])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 24, 24])\n",
            "  3% 91/3568 [00:41<26:07,  2.22it/s, train_loss=8.46]feats after linear torch.Size([16, 340, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 340, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 24, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 340])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 24, 24])\n",
            "  3% 92/3568 [00:41<27:57,  2.07it/s, train_loss=8.44]feats after linear torch.Size([16, 325, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 325, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 24, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 325])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 24, 24])\n",
            "  3% 93/3568 [00:42<29:55,  1.94it/s, train_loss=8.42]feats after linear torch.Size([16, 326, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 326, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 19, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 326])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 19, 19])\n",
            "  3% 94/3568 [00:42<30:08,  1.92it/s, train_loss=8.39]feats after linear torch.Size([16, 344, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 344, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 21, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 344])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 21, 21])\n",
            "  3% 95/3568 [00:43<28:58,  2.00it/s, train_loss=8.36]feats after linear torch.Size([16, 328, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 328, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 20, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 328])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 20, 20])\n",
            "  3% 96/3568 [00:43<27:30,  2.10it/s, train_loss=8.34]feats after linear torch.Size([16, 345, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 345, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 20, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 345])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 20, 20])\n",
            "  3% 97/3568 [00:44<27:33,  2.10it/s, train_loss=8.32]feats after linear torch.Size([16, 331, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 331, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 19, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 331])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 19, 19])\n",
            "  3% 98/3568 [00:44<27:13,  2.12it/s, train_loss=8.3]feats after linear torch.Size([16, 331, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 331, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 24, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 331])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 24, 24])\n",
            "  3% 99/3568 [00:44<26:25,  2.19it/s, train_loss=8.27]feats after linear torch.Size([16, 332, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 332, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 25, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 332])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 25, 25])\n",
            "  3% 100/3568 [00:45<25:43,  2.25it/s, train_loss=8.25]feats after linear torch.Size([16, 333, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 333, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 26, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 333])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 26, 26])\n",
            "  3% 101/3568 [00:45<25:19,  2.28it/s, train_loss=8.23]feats after linear torch.Size([16, 352, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 352, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 20, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 352])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 20, 20])\n",
            "  3% 102/3568 [00:46<25:00,  2.31it/s, train_loss=8.21]feats after linear torch.Size([16, 336, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 336, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 22, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 336])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 22, 22])\n",
            "  3% 103/3568 [00:46<24:46,  2.33it/s, train_loss=8.18]feats after linear torch.Size([16, 337, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 337, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 20, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 337])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 20, 20])\n",
            "  3% 104/3568 [00:47<24:34,  2.35it/s, train_loss=8.16]feats after linear torch.Size([16, 354, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 354, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 24, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 354])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 24, 24])\n",
            "  3% 105/3568 [00:47<25:06,  2.30it/s, train_loss=8.14]feats after linear torch.Size([16, 339, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 339, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 22, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 339])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 22, 22])\n",
            "  3% 106/3568 [00:48<43:14,  1.33it/s, train_loss=8.12]feats after linear torch.Size([16, 340, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 340, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 16, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 340])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 16, 16])\n",
            "  3% 107/3568 [00:49<40:04,  1.44it/s, train_loss=8.11]feats after linear torch.Size([16, 357, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 357, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 23, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 357])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 23, 23])\n",
            "  3% 108/3568 [00:50<37:20,  1.54it/s, train_loss=8.09]feats after linear torch.Size([16, 359, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 359, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 21, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 359])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 21, 21])\n",
            "  3% 109/3568 [00:50<34:31,  1.67it/s, train_loss=8.07]feats after linear torch.Size([16, 360, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 360, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 24, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 360])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 24, 24])\n",
            "  3% 110/3568 [00:51<32:12,  1.79it/s, train_loss=8.05]feats after linear torch.Size([16, 362, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 362, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 22, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 362])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 22, 22])\n",
            "  3% 111/3568 [00:51<31:22,  1.84it/s, train_loss=8.03]feats after linear torch.Size([16, 347, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 347, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 22, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 347])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 22, 22])\n",
            "  3% 112/3568 [00:51<29:47,  1.93it/s, train_loss=8.02]feats after linear torch.Size([16, 348, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 348, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 26, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 348])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 26, 26])\n",
            "  3% 113/3568 [00:52<29:25,  1.96it/s, train_loss=8]feats after linear torch.Size([16, 366, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 366, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 23, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 366])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 23, 23])\n",
            "  3% 114/3568 [00:52<28:42,  2.01it/s, train_loss=7.98]feats after linear torch.Size([16, 352, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 352, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 23, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 352])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 23, 23])\n",
            "  3% 115/3568 [00:53<28:48,  2.00it/s, train_loss=7.96]feats after linear torch.Size([16, 370, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 370, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 24, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 370])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 24, 24])\n",
            "  3% 116/3568 [00:54<30:17,  1.90it/s, train_loss=7.95]feats after linear torch.Size([16, 371, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 371, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 19, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 371])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 19, 19])\n",
            "  3% 117/3568 [00:54<30:36,  1.88it/s, train_loss=7.93]feats after linear torch.Size([16, 354, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 354, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 26, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 354])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 26, 26])\n",
            "  3% 118/3568 [00:55<29:49,  1.93it/s, train_loss=7.91]feats after linear torch.Size([16, 372, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 372, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 27, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 372])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 27, 27])\n",
            "  3% 119/3568 [00:55<30:25,  1.89it/s, train_loss=7.9]feats after linear torch.Size([16, 356, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 356, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 25, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 356])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 25, 25])\n",
            "  3% 120/3568 [00:56<29:34,  1.94it/s, train_loss=7.88]feats after linear torch.Size([16, 357, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 357, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 23, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 357])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 23, 23])\n",
            "  3% 121/3568 [00:56<28:56,  1.99it/s, train_loss=7.87]feats after linear torch.Size([16, 376, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 376, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 23, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 376])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 23, 23])\n",
            "  3% 122/3568 [00:57<28:24,  2.02it/s, train_loss=7.85]feats after linear torch.Size([16, 378, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 378, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 22, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 378])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 22, 22])\n",
            "  3% 123/3568 [00:57<28:35,  2.01it/s, train_loss=7.84]feats after linear torch.Size([16, 381, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 381, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 26, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 381])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 26, 26])\n",
            "  3% 124/3568 [00:58<28:24,  2.02it/s, train_loss=7.82]feats after linear torch.Size([16, 383, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 383, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 21, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 383])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 21, 21])\n",
            "  4% 125/3568 [00:58<28:20,  2.03it/s, train_loss=7.81]feats after linear torch.Size([16, 366, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 366, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 26, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 366])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 26, 26])\n",
            "  4% 126/3568 [00:59<27:44,  2.07it/s, train_loss=7.79]feats after linear torch.Size([16, 385, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 385, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 26, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 385])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 26, 26])\n",
            "  4% 127/3568 [00:59<29:17,  1.96it/s, train_loss=7.78]feats after linear torch.Size([16, 368, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 368, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 22, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 368])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 22, 22])\n",
            "  4% 128/3568 [01:00<28:59,  1.98it/s, train_loss=7.76]feats after linear torch.Size([16, 369, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 369, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 23, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 369])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 23, 23])\n",
            "  4% 129/3568 [01:00<28:20,  2.02it/s, train_loss=7.75]feats after linear torch.Size([16, 371, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 371, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 26, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 371])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 26, 26])\n",
            "  4% 130/3568 [01:01<29:14,  1.96it/s, train_loss=7.74]feats after linear torch.Size([16, 372, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 372, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 17, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 372])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 17, 17])\n",
            "  4% 131/3568 [01:01<28:24,  2.02it/s, train_loss=7.73]feats after linear torch.Size([16, 373, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 373, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 22, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 373])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 22, 22])\n",
            "  4% 132/3568 [01:02<28:16,  2.03it/s, train_loss=7.71]feats after linear torch.Size([16, 374, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 374, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 27, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 374])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 27, 27])\n",
            "  4% 133/3568 [01:02<27:49,  2.06it/s, train_loss=7.7]feats after linear torch.Size([16, 375, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 375, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 29, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 375])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 29, 29])\n",
            "  4% 134/3568 [01:02<27:52,  2.05it/s, train_loss=7.69]feats after linear torch.Size([16, 394, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 394, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 31, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 394])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 31, 31])\n",
            "  4% 135/3568 [01:03<28:09,  2.03it/s, train_loss=7.68]feats after linear torch.Size([16, 396, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 396, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 26, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 396])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 26, 26])\n",
            "  4% 136/3568 [01:03<28:09,  2.03it/s, train_loss=7.66]feats after linear torch.Size([16, 378, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 378, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 22, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 378])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 22, 22])\n",
            "  4% 137/3568 [01:04<29:22,  1.95it/s, train_loss=7.65]feats after linear torch.Size([16, 379, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 379, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 21, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 379])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 21, 21])\n",
            "  4% 138/3568 [01:05<29:58,  1.91it/s, train_loss=7.64]feats after linear torch.Size([16, 380, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 380, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 26, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 380])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 26, 26])\n",
            "  4% 139/3568 [01:05<29:34,  1.93it/s, train_loss=7.63]feats after linear torch.Size([16, 381, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 381, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 24, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 381])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 24, 24])\n",
            "  4% 140/3568 [01:06<29:07,  1.96it/s, train_loss=7.62]feats after linear torch.Size([16, 381, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 381, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 26, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 381])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 26, 26])\n",
            "  4% 141/3568 [01:06<29:43,  1.92it/s, train_loss=7.61]feats after linear torch.Size([16, 382, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 382, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 31, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 382])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 31, 31])\n",
            "  4% 142/3568 [01:07<30:37,  1.86it/s, train_loss=7.59]feats after linear torch.Size([16, 402, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 402, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 30, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 402])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 30, 30])\n",
            "  4% 143/3568 [01:07<31:38,  1.80it/s, train_loss=7.58]feats after linear torch.Size([16, 384, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 384, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 24, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 384])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 24, 24])\n",
            "  4% 144/3568 [01:08<32:05,  1.78it/s, train_loss=7.57]feats after linear torch.Size([16, 385, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 385, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 23, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 385])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 23, 23])\n",
            "  4% 145/3568 [01:09<32:54,  1.73it/s, train_loss=7.56]feats after linear torch.Size([16, 387, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 387, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 23, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 387])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 23, 23])\n",
            "  4% 146/3568 [01:09<32:18,  1.76it/s, train_loss=7.55]feats after linear torch.Size([16, 408, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 408, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 25, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 408])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 25, 25])\n",
            "  4% 147/3568 [01:10<31:31,  1.81it/s, train_loss=7.54]feats after linear torch.Size([16, 391, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 391, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 30, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 391])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 30, 30])\n",
            "  4% 148/3568 [01:10<31:14,  1.82it/s, train_loss=7.53]feats after linear torch.Size([16, 391, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 391, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 23, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 391])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 23, 23])\n",
            "  4% 149/3568 [01:11<30:28,  1.87it/s, train_loss=7.52]feats after linear torch.Size([16, 411, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 411, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 26, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 411])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 26, 26])\n",
            "  4% 150/3568 [01:11<30:34,  1.86it/s, train_loss=7.51]feats after linear torch.Size([16, 413, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 413, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 24, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 413])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 24, 24])\n",
            "  4% 151/3568 [01:12<32:49,  1.73it/s, train_loss=7.5]feats after linear torch.Size([16, 414, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 414, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 24, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 414])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 24, 24])\n",
            "  4% 152/3568 [01:12<31:34,  1.80it/s, train_loss=7.49]feats after linear torch.Size([16, 395, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 395, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 24, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 395])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 24, 24])\n",
            "  4% 153/3568 [01:13<31:01,  1.83it/s, train_loss=7.48]feats after linear torch.Size([16, 396, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 396, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 22, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 396])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 22, 22])\n",
            "  4% 154/3568 [01:13<30:13,  1.88it/s, train_loss=7.47]feats after linear torch.Size([16, 397, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 397, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 26, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 397])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 26, 26])\n",
            "  4% 155/3568 [01:14<30:20,  1.88it/s, train_loss=7.47]feats after linear torch.Size([16, 417, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 417, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 29, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 417])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 29, 29])\n",
            "  4% 156/3568 [01:14<30:47,  1.85it/s, train_loss=7.46]feats after linear torch.Size([16, 399, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 399, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 25, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 399])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 25, 25])\n",
            "  4% 157/3568 [01:15<30:30,  1.86it/s, train_loss=7.45]feats after linear torch.Size([16, 399, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 399, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 27, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 399])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 27, 27])\n",
            "  4% 158/3568 [01:16<30:51,  1.84it/s, train_loss=7.44]feats after linear torch.Size([16, 401, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 401, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 31, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 401])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 31, 31])\n",
            "  4% 159/3568 [01:16<30:51,  1.84it/s, train_loss=7.43]feats after linear torch.Size([16, 423, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 423, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 23, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 423])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 23, 23])\n",
            "  4% 160/3568 [01:17<31:53,  1.78it/s, train_loss=7.42]feats after linear torch.Size([16, 404, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 404, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 22, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 404])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 22, 22])\n",
            "  5% 161/3568 [01:17<31:24,  1.81it/s, train_loss=7.41]feats after linear torch.Size([16, 405, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 405, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 24, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 405])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 24, 24])\n",
            "  5% 162/3568 [01:18<30:41,  1.85it/s, train_loss=7.4]feats after linear torch.Size([16, 426, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 426, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 31, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 426])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 31, 31])\n",
            "  5% 163/3568 [01:18<31:00,  1.83it/s, train_loss=7.39]feats after linear torch.Size([16, 427, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 427, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 28, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 427])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 28, 28])\n",
            "  5% 164/3568 [01:19<32:23,  1.75it/s, train_loss=7.38]feats after linear torch.Size([16, 408, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 408, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 23, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 408])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 23, 23])\n",
            "  5% 165/3568 [01:20<36:25,  1.56it/s, train_loss=7.38]feats after linear torch.Size([16, 409, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 409, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 26, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 409])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 26, 26])\n",
            "  5% 166/3568 [01:20<34:43,  1.63it/s, train_loss=7.37]feats after linear torch.Size([16, 411, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 411, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 30, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 411])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 30, 30])\n",
            "  5% 167/3568 [01:21<35:15,  1.61it/s, train_loss=7.36]feats after linear torch.Size([16, 412, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 412, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 24, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 412])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 24, 24])\n",
            "  5% 168/3568 [01:21<33:39,  1.68it/s, train_loss=7.35]feats after linear torch.Size([16, 434, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 434, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 29, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 434])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 29, 29])\n",
            "  5% 169/3568 [01:22<32:41,  1.73it/s, train_loss=7.35]feats after linear torch.Size([16, 415, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 415, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 24, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 415])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 24, 24])\n",
            "  5% 170/3568 [01:23<31:55,  1.77it/s, train_loss=7.34]feats after linear torch.Size([16, 436, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 436, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 32, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 436])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 32, 32])\n",
            "  5% 171/3568 [01:23<31:18,  1.81it/s, train_loss=7.33]feats after linear torch.Size([16, 438, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 438, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 32, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 438])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 32, 32])\n",
            "  5% 172/3568 [01:24<31:19,  1.81it/s, train_loss=7.32]feats after linear torch.Size([16, 419, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 419, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 23, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 419])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 23, 23])\n",
            "  5% 173/3568 [01:24<31:19,  1.81it/s, train_loss=7.31]feats after linear torch.Size([16, 420, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 420, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 30, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 420])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 30, 30])\n",
            "  5% 174/3568 [01:25<31:00,  1.82it/s, train_loss=7.31]feats after linear torch.Size([16, 442, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 442, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 31, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 442])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 31, 31])\n",
            "  5% 175/3568 [01:25<31:04,  1.82it/s, train_loss=7.3]feats after linear torch.Size([16, 422, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 422, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 27, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 422])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 27, 27])\n",
            "  5% 176/3568 [01:26<30:55,  1.83it/s, train_loss=7.29]feats after linear torch.Size([16, 423, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 423, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 24, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 423])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 24, 24])\n",
            "  5% 177/3568 [01:26<30:53,  1.83it/s, train_loss=7.29]feats after linear torch.Size([16, 446, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 446, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 29, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 446])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 29, 29])\n",
            "  5% 178/3568 [01:27<31:17,  1.81it/s, train_loss=7.28]feats after linear torch.Size([16, 447, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 447, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 31, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 447])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 31, 31])\n",
            "  5% 179/3568 [01:27<31:03,  1.82it/s, train_loss=7.27]feats after linear torch.Size([16, 449, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 449, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 28, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 449])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 28, 28])\n",
            "  5% 180/3568 [01:28<31:28,  1.79it/s, train_loss=7.27]feats after linear torch.Size([16, 428, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 428, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 26, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 428])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 26, 26])\n",
            "  5% 181/3568 [01:29<31:14,  1.81it/s, train_loss=7.26]feats after linear torch.Size([16, 430, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 430, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 30, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 430])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 30, 30])\n",
            "  5% 182/3568 [01:29<31:03,  1.82it/s, train_loss=7.25]feats after linear torch.Size([16, 452, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 452, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 26, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 452])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 26, 26])\n",
            "  5% 183/3568 [01:30<31:25,  1.80it/s, train_loss=7.24]feats after linear torch.Size([16, 432, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 432, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 25, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 432])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 25, 25])\n",
            "  5% 184/3568 [01:30<31:24,  1.80it/s, train_loss=7.24]feats after linear torch.Size([16, 455, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 455, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 28, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 455])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 28, 28])\n",
            "  5% 185/3568 [01:31<31:26,  1.79it/s, train_loss=7.23]feats after linear torch.Size([16, 457, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 457, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 28, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 457])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 28, 28])\n",
            "  5% 186/3568 [01:31<32:52,  1.71it/s, train_loss=7.22]feats after linear torch.Size([16, 460, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 460, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 29, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 460])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 29, 29])\n",
            "  5% 187/3568 [01:32<33:03,  1.70it/s, train_loss=7.22]feats after linear torch.Size([16, 460, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 460, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 29, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 460])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 29, 29])\n",
            "  5% 188/3568 [01:33<33:54,  1.66it/s, train_loss=7.21]feats after linear torch.Size([16, 440, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 440, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 27, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 440])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 27, 27])\n",
            "  5% 189/3568 [01:33<33:44,  1.67it/s, train_loss=7.2]feats after linear torch.Size([16, 462, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 462, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 31, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 462])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 31, 31])\n",
            "  5% 190/3568 [01:34<33:23,  1.69it/s, train_loss=7.2]feats after linear torch.Size([16, 442, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 442, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 29, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 442])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 29, 29])\n",
            "  5% 191/3568 [01:34<34:29,  1.63it/s, train_loss=7.19]feats after linear torch.Size([16, 465, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 465, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 31, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 465])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 31, 31])\n",
            "  5% 192/3568 [01:35<34:28,  1.63it/s, train_loss=7.18]feats after linear torch.Size([16, 444, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 444, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 34, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 444])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 34, 34])\n",
            "  5% 193/3568 [01:36<33:40,  1.67it/s, train_loss=7.18]feats after linear torch.Size([16, 445, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 445, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 35, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 445])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 35, 35])\n",
            "  5% 194/3568 [01:36<32:58,  1.71it/s, train_loss=7.17]feats after linear torch.Size([16, 469, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 469, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 28, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 469])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 28, 28])\n",
            "  5% 195/3568 [01:37<33:04,  1.70it/s, train_loss=7.16]feats after linear torch.Size([16, 470, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 470, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 30, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 470])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 30, 30])\n",
            "  5% 196/3568 [01:37<33:14,  1.69it/s, train_loss=7.16]feats after linear torch.Size([16, 449, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 449, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 28, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 449])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 28, 28])\n",
            "  6% 197/3568 [01:38<33:01,  1.70it/s, train_loss=7.15]feats after linear torch.Size([16, 450, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 450, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 31, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 450])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 31, 31])\n",
            "  6% 198/3568 [01:39<33:58,  1.65it/s, train_loss=7.15]feats after linear torch.Size([16, 450, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 450, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 29, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 450])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 29, 29])\n",
            "  6% 199/3568 [01:39<34:10,  1.64it/s, train_loss=7.14]feats after linear torch.Size([16, 452, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 452, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 35, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 452])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 35, 35])\n",
            "  6% 200/3568 [01:40<34:06,  1.65it/s, train_loss=7.13]feats after linear torch.Size([16, 476, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 476, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 32, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 476])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 32, 32])\n",
            "  6% 201/3568 [01:40<34:06,  1.65it/s, train_loss=7.13]feats after linear torch.Size([16, 454, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 454, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 30, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 454])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 30, 30])\n",
            "  6% 202/3568 [01:41<33:56,  1.65it/s, train_loss=7.12]feats after linear torch.Size([16, 456, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 456, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 32, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 456])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 32, 32])\n",
            "  6% 203/3568 [01:42<33:41,  1.66it/s, train_loss=7.12]feats after linear torch.Size([16, 457, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 457, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 28, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 457])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 28, 28])\n",
            "  6% 204/3568 [01:42<33:31,  1.67it/s, train_loss=7.11]feats after linear torch.Size([16, 458, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 458, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 28, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 458])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 28, 28])\n",
            "  6% 205/3568 [01:43<33:04,  1.69it/s, train_loss=7.11]feats after linear torch.Size([16, 459, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 459, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 33, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 459])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 33, 33])\n",
            "  6% 206/3568 [01:43<33:06,  1.69it/s, train_loss=7.1]feats after linear torch.Size([16, 483, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 483, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 30, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 483])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 30, 30])\n",
            "  6% 207/3568 [01:44<33:19,  1.68it/s, train_loss=7.1]feats after linear torch.Size([16, 461, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 461, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 32, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 461])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 32, 32])\n",
            "  6% 208/3568 [01:45<32:51,  1.70it/s, train_loss=7.09]feats after linear torch.Size([16, 485, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 485, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 31, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 485])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 31, 31])\n",
            "  6% 209/3568 [01:45<32:51,  1.70it/s, train_loss=7.09]feats after linear torch.Size([16, 486, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 486, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 26, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 486])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 26, 26])\n",
            "  6% 210/3568 [01:46<33:12,  1.69it/s, train_loss=7.08]feats after linear torch.Size([16, 464, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 464, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 29, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 464])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 29, 29])\n",
            "  6% 211/3568 [01:48<56:13,  1.00s/it, train_loss=7.08]feats after linear torch.Size([16, 465, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 465, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 33, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 465])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 33, 33])\n",
            "  6% 212/3568 [01:48<51:09,  1.09it/s, train_loss=7.07]feats after linear torch.Size([16, 467, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 467, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 30, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 467])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 30, 30])\n",
            "  6% 213/3568 [01:49<46:22,  1.21it/s, train_loss=7.06]feats after linear torch.Size([16, 491, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 491, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 31, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 491])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 31, 31])\n",
            "  6% 214/3568 [01:50<42:56,  1.30it/s, train_loss=7.06]feats after linear torch.Size([16, 469, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 469, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 28, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 469])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 28, 28])\n",
            "  6% 215/3568 [01:50<40:11,  1.39it/s, train_loss=7.05]feats after linear torch.Size([16, 493, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 493, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 29, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 493])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 29, 29])\n",
            "  6% 216/3568 [01:51<38:33,  1.45it/s, train_loss=7.05]feats after linear torch.Size([16, 496, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 496, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 28, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 496])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 28, 28])\n",
            "  6% 217/3568 [01:52<37:21,  1.50it/s, train_loss=7.04]feats after linear torch.Size([16, 497, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 497, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 31, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 497])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 31, 31])\n",
            "  6% 218/3568 [01:52<37:50,  1.48it/s, train_loss=7.04]feats after linear torch.Size([16, 476, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 476, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 30, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 476])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 30, 30])\n",
            "  6% 219/3568 [01:53<36:31,  1.53it/s, train_loss=7.03]feats after linear torch.Size([16, 500, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 500, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 26, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 500])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 26, 26])\n",
            "  6% 220/3568 [01:54<36:30,  1.53it/s, train_loss=7.03]feats after linear torch.Size([16, 478, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 478, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 34, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 478])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 34, 34])\n",
            "  6% 221/3568 [01:54<36:02,  1.55it/s, train_loss=7.02]feats after linear torch.Size([16, 479, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 479, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 24, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 479])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 24, 24])\n",
            "  6% 222/3568 [01:55<35:08,  1.59it/s, train_loss=7.02]feats after linear torch.Size([16, 480, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 480, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 29, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 480])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 29, 29])\n",
            "  6% 223/3568 [01:55<34:31,  1.61it/s, train_loss=7.01]feats after linear torch.Size([16, 481, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 481, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 28, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 481])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 28, 28])\n",
            "  6% 224/3568 [01:56<34:44,  1.60it/s, train_loss=7.01]feats after linear torch.Size([16, 483, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 483, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 29, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 483])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 29, 29])\n",
            "  6% 225/3568 [01:57<34:57,  1.59it/s, train_loss=7.01]feats after linear torch.Size([16, 508, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 508, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 31, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 508])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 31, 31])\n",
            "  6% 226/3568 [01:57<35:34,  1.57it/s, train_loss=7]feats after linear torch.Size([16, 486, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 486, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 40, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 486])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 40, 40])\n",
            "  6% 227/3568 [01:58<36:45,  1.51it/s, train_loss=7]feats after linear torch.Size([16, 487, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 487, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 27, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 487])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 27, 27])\n",
            "  6% 228/3568 [01:59<38:14,  1.46it/s, train_loss=6.99]feats after linear torch.Size([16, 488, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 488, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 32, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 488])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 32, 32])\n",
            "  6% 229/3568 [01:59<37:20,  1.49it/s, train_loss=6.99]feats after linear torch.Size([16, 489, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 489, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 33, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 489])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 33, 33])\n",
            "  6% 230/3568 [02:00<36:57,  1.51it/s, train_loss=6.98]feats after linear torch.Size([16, 489, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 489, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 33, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 489])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 33, 33])\n",
            "  6% 231/3568 [02:01<36:42,  1.51it/s, train_loss=6.98]feats after linear torch.Size([16, 490, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 490, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 34, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 490])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 34, 34])\n",
            "  7% 232/3568 [02:01<37:29,  1.48it/s, train_loss=6.97]feats after linear torch.Size([16, 516, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 516, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 31, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 516])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 31, 31])\n",
            "  7% 233/3568 [02:02<38:01,  1.46it/s, train_loss=6.97]feats after linear torch.Size([16, 492, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 492, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 30, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 492])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 30, 30])\n",
            "  7% 234/3568 [02:03<36:58,  1.50it/s, train_loss=6.97]feats after linear torch.Size([16, 518, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 518, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 29, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 518])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 29, 29])\n",
            "  7% 235/3568 [02:03<37:50,  1.47it/s, train_loss=6.96]feats after linear torch.Size([16, 518, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 518, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 29, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 518])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 29, 29])\n",
            "  7% 236/3568 [02:04<38:09,  1.46it/s, train_loss=6.96]feats after linear torch.Size([16, 495, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 495, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 39, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 495])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 39, 39])\n",
            "  7% 237/3568 [02:05<37:44,  1.47it/s, train_loss=6.95]feats after linear torch.Size([16, 496, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 496, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 33, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 496])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 33, 33])\n",
            "  7% 238/3568 [02:05<36:38,  1.51it/s, train_loss=6.95]feats after linear torch.Size([16, 497, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 497, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 34, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 497])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 34, 34])\n",
            "  7% 239/3568 [02:06<37:02,  1.50it/s, train_loss=6.94]feats after linear torch.Size([16, 498, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 498, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 32, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 498])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 32, 32])\n",
            "  7% 240/3568 [02:07<37:16,  1.49it/s, train_loss=6.94]feats after linear torch.Size([16, 499, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 499, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 32, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 499])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 32, 32])\n",
            "  7% 241/3568 [02:07<37:05,  1.49it/s, train_loss=6.94]feats after linear torch.Size([16, 524, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 524, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 35, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 524])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 35, 35])\n",
            "  7% 242/3568 [02:08<39:16,  1.41it/s, train_loss=6.93]feats after linear torch.Size([16, 501, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 501, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 32, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 501])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 32, 32])\n",
            "  7% 243/3568 [02:09<38:59,  1.42it/s, train_loss=6.93]feats after linear torch.Size([16, 502, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 502, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 35, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 502])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 35, 35])\n",
            "  7% 244/3568 [02:10<38:24,  1.44it/s, train_loss=6.92]feats after linear torch.Size([16, 502, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 502, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 34, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 502])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 34, 34])\n",
            "  7% 245/3568 [02:10<37:54,  1.46it/s, train_loss=6.92]feats after linear torch.Size([16, 504, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 504, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 29, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 504])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 29, 29])\n",
            "  7% 246/3568 [02:11<37:01,  1.50it/s, train_loss=6.91]feats after linear torch.Size([16, 531, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 531, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 32, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 531])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 32, 32])\n",
            "  7% 247/3568 [02:12<39:23,  1.40it/s, train_loss=6.91]feats after linear torch.Size([16, 532, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 532, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 28, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 532])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 28, 28])\n",
            "  7% 248/3568 [02:12<40:53,  1.35it/s, train_loss=6.91]feats after linear torch.Size([16, 508, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 508, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 30, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 508])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 30, 30])\n",
            "  7% 249/3568 [02:13<40:11,  1.38it/s, train_loss=6.9]feats after linear torch.Size([16, 534, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 534, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 30, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 534])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 30, 30])\n",
            "  7% 250/3568 [02:14<40:20,  1.37it/s, train_loss=6.9]feats after linear torch.Size([16, 511, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 511, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 32, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 511])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 32, 32])\n",
            "  7% 251/3568 [02:15<39:25,  1.40it/s, train_loss=6.89]feats after linear torch.Size([16, 538, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 538, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 32, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 538])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 32, 32])\n",
            "  7% 252/3568 [02:15<40:16,  1.37it/s, train_loss=6.89]feats after linear torch.Size([16, 539, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 539, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 30, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 539])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 30, 30])\n",
            "  7% 253/3568 [02:16<41:53,  1.32it/s, train_loss=6.89]feats after linear torch.Size([16, 514, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 514, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 35, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 514])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 35, 35])\n",
            "  7% 254/3568 [02:17<41:35,  1.33it/s, train_loss=6.88]feats after linear torch.Size([16, 516, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 516, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 30, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 516])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 30, 30])\n",
            "  7% 255/3568 [02:18<41:19,  1.34it/s, train_loss=6.88]feats after linear torch.Size([16, 542, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 542, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 34, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 542])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 34, 34])\n",
            "  7% 256/3568 [02:19<43:22,  1.27it/s, train_loss=6.88]feats after linear torch.Size([16, 544, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 544, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 34, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 544])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 34, 34])\n",
            "  7% 257/3568 [02:19<43:04,  1.28it/s, train_loss=6.87]feats after linear torch.Size([16, 544, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 544, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 33, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 544])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 33, 33])\n",
            "  7% 258/3568 [02:20<43:09,  1.28it/s, train_loss=6.87]feats after linear torch.Size([16, 521, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 521, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 31, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 521])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 31, 31])\n",
            "  7% 259/3568 [02:21<42:55,  1.28it/s, train_loss=6.86]feats after linear torch.Size([16, 521, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 521, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 31, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 521])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 31, 31])\n",
            "  7% 260/3568 [02:22<42:56,  1.28it/s, train_loss=6.86]feats after linear torch.Size([16, 549, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 549, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 30, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 549])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 30, 30])\n",
            "  7% 261/3568 [02:22<42:40,  1.29it/s, train_loss=6.86]feats after linear torch.Size([16, 524, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 524, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 33, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 524])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 33, 33])\n",
            "  7% 262/3568 [02:23<44:57,  1.23it/s, train_loss=6.85]feats after linear torch.Size([16, 551, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 551, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 31, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 551])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 31, 31])\n",
            "  7% 263/3568 [02:24<45:05,  1.22it/s, train_loss=6.85]feats after linear torch.Size([16, 527, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 527, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 33, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 527])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 33, 33])\n",
            "  7% 264/3568 [02:25<44:57,  1.22it/s, train_loss=6.85]feats after linear torch.Size([16, 554, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 554, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 32, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 554])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 32, 32])\n",
            "  7% 265/3568 [02:26<46:24,  1.19it/s, train_loss=6.84]feats after linear torch.Size([16, 529, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 529, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 33, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 529])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 33, 33])\n",
            "  7% 266/3568 [02:27<45:06,  1.22it/s, train_loss=6.84]feats after linear torch.Size([16, 557, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 557, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 33, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 557])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 33, 33])\n",
            "  7% 267/3568 [02:27<43:49,  1.26it/s, train_loss=6.84]feats after linear torch.Size([16, 558, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 558, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 35, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 558])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 35, 35])\n",
            "  8% 268/3568 [02:28<43:38,  1.26it/s, train_loss=6.83]feats after linear torch.Size([16, 559, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 559, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 36, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 559])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 36, 36])\n",
            "  8% 269/3568 [02:29<42:58,  1.28it/s, train_loss=6.83]feats after linear torch.Size([16, 534, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 534, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 33, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 534])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 33, 33])\n",
            "  8% 270/3568 [02:30<44:42,  1.23it/s, train_loss=6.83]feats after linear torch.Size([16, 562, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 562, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 33, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 562])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 33, 33])\n",
            "  8% 271/3568 [02:31<44:19,  1.24it/s, train_loss=6.82]feats after linear torch.Size([16, 536, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 536, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 33, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 536])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 33, 33])\n",
            "  8% 272/3568 [02:31<43:19,  1.27it/s, train_loss=6.82]feats after linear torch.Size([16, 537, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 537, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 32, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 537])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 32, 32])\n",
            "  8% 273/3568 [02:32<43:10,  1.27it/s, train_loss=6.82]feats after linear torch.Size([16, 538, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 538, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 32, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 538])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 32, 32])\n",
            "  8% 274/3568 [02:33<43:04,  1.27it/s, train_loss=6.81]feats after linear torch.Size([16, 540, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 540, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 38, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 540])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 38, 38])\n",
            "  8% 275/3568 [02:34<42:47,  1.28it/s, train_loss=6.81]feats after linear torch.Size([16, 542, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 542, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 32, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 542])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 32, 32])\n",
            "  8% 276/3568 [02:34<42:16,  1.30it/s, train_loss=6.81]feats after linear torch.Size([16, 570, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 570, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 36, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 570])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 36, 36])\n",
            "  8% 277/3568 [02:35<42:58,  1.28it/s, train_loss=6.8]feats after linear torch.Size([16, 571, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 571, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 38, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 571])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 38, 38])\n",
            "  8% 278/3568 [02:36<44:18,  1.24it/s, train_loss=6.8]feats after linear torch.Size([16, 545, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 545, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 42, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 545])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 42, 42])\n",
            "  8% 279/3568 [02:37<44:36,  1.23it/s, train_loss=6.8]feats after linear torch.Size([16, 546, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 546, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 35, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 546])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 35, 35])\n",
            "  8% 280/3568 [02:38<44:37,  1.23it/s, train_loss=6.8]feats after linear torch.Size([16, 547, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 547, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 34, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 547])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 34, 34])\n",
            "  8% 281/3568 [02:39<44:13,  1.24it/s, train_loss=6.79]feats after linear torch.Size([16, 575, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 575, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 33, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 575])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 33, 33])\n",
            "  8% 282/3568 [02:39<44:12,  1.24it/s, train_loss=6.79]feats after linear torch.Size([16, 549, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 549, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 36, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 549])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 36, 36])\n",
            "  8% 283/3568 [02:40<44:09,  1.24it/s, train_loss=6.79]feats after linear torch.Size([16, 579, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 579, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 33, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 579])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 33, 33])\n",
            "  8% 284/3568 [02:41<44:21,  1.23it/s, train_loss=6.78]feats after linear torch.Size([16, 580, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 580, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 38, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 580])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 38, 38])\n",
            "  8% 285/3568 [02:42<44:36,  1.23it/s, train_loss=6.78]feats after linear torch.Size([16, 554, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 554, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 37, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 554])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 37, 37])\n",
            "  8% 286/3568 [02:43<44:09,  1.24it/s, train_loss=6.78]feats after linear torch.Size([16, 556, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 556, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 39, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 556])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 39, 39])\n",
            "  8% 287/3568 [02:43<43:43,  1.25it/s, train_loss=6.78]feats after linear torch.Size([16, 585, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 585, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 41, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 585])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 41, 41])\n",
            "  8% 288/3568 [02:44<44:53,  1.22it/s, train_loss=6.77]feats after linear torch.Size([16, 558, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 558, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 33, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 558])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 33, 33])\n",
            "  8% 289/3568 [02:45<43:41,  1.25it/s, train_loss=6.77]feats after linear torch.Size([16, 559, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 559, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 35, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 559])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 35, 35])\n",
            "  8% 290/3568 [02:46<42:52,  1.27it/s, train_loss=6.77]feats after linear torch.Size([16, 560, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 560, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 29, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 560])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 29, 29])\n",
            "  8% 291/3568 [02:47<43:23,  1.26it/s, train_loss=6.76]feats after linear torch.Size([16, 562, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 562, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 36, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 562])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 36, 36])\n",
            "  8% 292/3568 [02:47<43:21,  1.26it/s, train_loss=6.76]feats after linear torch.Size([16, 564, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 564, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 38, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 564])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 38, 38])\n",
            "  8% 293/3568 [02:48<43:21,  1.26it/s, train_loss=6.76]feats after linear torch.Size([16, 593, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 593, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 39, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 593])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 39, 39])\n",
            "  8% 294/3568 [02:49<44:24,  1.23it/s, train_loss=6.76]feats after linear torch.Size([16, 567, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 567, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 33, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 567])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 33, 33])\n",
            "  8% 295/3568 [02:50<44:35,  1.22it/s, train_loss=6.75]feats after linear torch.Size([16, 596, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 596, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 34, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 596])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 34, 34])\n",
            "  8% 296/3568 [02:51<45:16,  1.20it/s, train_loss=6.75]feats after linear torch.Size([16, 597, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 597, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 34, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 597])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 34, 34])\n",
            "  8% 297/3568 [02:51<44:18,  1.23it/s, train_loss=6.75]feats after linear torch.Size([16, 570, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 570, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 36, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 570])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 36, 36])\n",
            "  8% 298/3568 [02:52<43:38,  1.25it/s, train_loss=6.74]feats after linear torch.Size([16, 572, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 572, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 34, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 572])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 34, 34])\n",
            "  8% 299/3568 [02:53<43:39,  1.25it/s, train_loss=6.74]feats after linear torch.Size([16, 572, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 572, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 30, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 572])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 30, 30])\n",
            "  8% 300/3568 [02:54<43:47,  1.24it/s, train_loss=6.74]feats after linear torch.Size([16, 573, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 573, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 35, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 573])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 35, 35])\n",
            "  8% 301/3568 [02:55<42:54,  1.27it/s, train_loss=6.74]feats after linear torch.Size([16, 602, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 602, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 57, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 602])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 57, 57])\n",
            "  8% 302/3568 [02:55<44:22,  1.23it/s, train_loss=6.73]feats after linear torch.Size([16, 603, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 603, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 37, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 603])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 37, 37])\n",
            "  8% 303/3568 [02:56<46:12,  1.18it/s, train_loss=6.73]feats after linear torch.Size([16, 576, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 576, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 36, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 576])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 36, 36])\n",
            "  9% 304/3568 [02:57<45:04,  1.21it/s, train_loss=6.73]feats after linear torch.Size([16, 605, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 605, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 35, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 605])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 35, 35])\n",
            "  9% 305/3568 [02:58<44:42,  1.22it/s, train_loss=6.73]feats after linear torch.Size([16, 578, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 578, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 40, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 578])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 40, 40])\n",
            "  9% 306/3568 [02:59<44:39,  1.22it/s, train_loss=6.72]feats after linear torch.Size([16, 579, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 579, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 31, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 579])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 31, 31])\n",
            "  9% 307/3568 [03:00<44:49,  1.21it/s, train_loss=6.72]feats after linear torch.Size([16, 581, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 581, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 43, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 581])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 43, 43])\n",
            "  9% 308/3568 [03:00<44:34,  1.22it/s, train_loss=6.72]feats after linear torch.Size([16, 582, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 582, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 39, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 582])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 39, 39])\n",
            "  9% 309/3568 [03:01<44:00,  1.23it/s, train_loss=6.72]feats after linear torch.Size([16, 583, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 583, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 33, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 583])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 33, 33])\n",
            "  9% 310/3568 [03:02<43:16,  1.25it/s, train_loss=6.71]feats after linear torch.Size([16, 586, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 586, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 34, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 586])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 34, 34])\n",
            "  9% 311/3568 [03:03<43:09,  1.26it/s, train_loss=6.71]feats after linear torch.Size([16, 616, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 616, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 35, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 616])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 35, 35])\n",
            "  9% 312/3568 [03:04<43:13,  1.26it/s, train_loss=6.71]feats after linear torch.Size([16, 589, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 589, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 35, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 589])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 35, 35])\n",
            "  9% 313/3568 [03:04<42:48,  1.27it/s, train_loss=6.7]feats after linear torch.Size([16, 590, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 590, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 39, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 590])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 39, 39])\n",
            "  9% 314/3568 [03:05<42:32,  1.27it/s, train_loss=6.7]feats after linear torch.Size([16, 621, 1024])\n",
            "\n",
            " encoded states torch.Size([16, 621, 1024])\n",
            "\n",
            " emb tokens  torch.Size([16, 43, 128])\n",
            "\n",
            " src mask torch.Size([16, 1, 1, 621])\n",
            "\n",
            " tgt mask torch.Size([1, 1, 43, 43])\n",
            "  9% 315/3568 [03:06<43:06,  1.26it/s, train_loss=6.7]"
          ]
        }
      ],
      "source": [
        "!python train.py hparams/mamba_BPE_1000.yaml"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}